{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CMU_049_06.hdf5', 'CMU_049_07.hdf5']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "\n",
    "root = '/home/yigit/projects/mbcnp/data/raw/mocapact/'\n",
    "files = []\n",
    "\n",
    "# Iterate directory\n",
    "for file_path in os.listdir(root):\n",
    "    if file_path.endswith('.hdf5') and os.path.isfile(os.path.join(root, file_path)):\n",
    "        # add filename to list\n",
    "        files.append(file_path)\n",
    "print(files)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "desired_observables = ['actuator_activation', 'joints_pos', 'joints_vel', 'sensors_gyro', 'end_effectors_pos', \n",
    "                       'sensors_torque', 'sensors_touch', 'sensors_velocimeter', 'world_zaxis']\n",
    "\n",
    "def get_obs_indices(path):\n",
    "    indices = []\n",
    "\n",
    "    f = h5py.File(path, 'r+')\n",
    "    walker_obs_dict = f['observable_indices']['walker']\n",
    "    for k in walker_obs_dict.keys():\n",
    "        if k in desired_observables:\n",
    "            dum = walker_obs_dict[k][:]\n",
    "            indices.extend(dum)\n",
    "    f.close()\n",
    "\n",
    "    return np.array(indices)\n",
    "\n",
    "# Get indices\n",
    "indices = get_obs_indices(os.path.join(root, 'CMU_049_06.hdf5'))\n",
    "\n",
    "#region read mocapact data\n",
    "full_obs, full_act = [], []\n",
    "\n",
    "for file in files:\n",
    "    fp = os.path.join(root, file)\n",
    "    # Open file\n",
    "    f = h5py.File(fp, 'r+')\n",
    "\n",
    "    demos = {}\n",
    "\n",
    "    num_start_rollouts = f['n_start_rollouts'][()]  # concatenate snippets to create this many rollouts\n",
    "    for i in range(num_start_rollouts):\n",
    "        demos.update({i: {}})\n",
    "        demos[i].update({'obs': {}})\n",
    "        demos[i].update({'act': {}})\n",
    "    \n",
    "    num_snippets = 0\n",
    "    for key in f.keys():\n",
    "        if key.startswith('CMU_'):\n",
    "            num_snippets += 1\n",
    "\n",
    "    for key in f.keys():\n",
    "        if key.startswith('CMU_'):\n",
    "            start, end = int(key.split('-')[-2]), int(key.split('-')[-1])\n",
    "            for i in range(num_start_rollouts):\n",
    "                obs = np.array(f[key][str(i)]['observations']['proprioceptive'])\n",
    "                act = np.array(f[key][str(i)]['actions'])\n",
    "                for j in range(len(act)):\n",
    "                    demos[i]['obs'].update({start+j: obs[j, indices]})\n",
    "                    demos[i]['act'].update({start+j: act[j]})\n",
    "\n",
    "    for key in f.keys():\n",
    "        for i in range(num_start_rollouts):\n",
    "            if key.startswith('CMU_') and f[key]['early_termination'][i] == True:\n",
    "                if i in demos.keys():\n",
    "                    demos.pop(i)\n",
    "\n",
    "    for key in demos.keys():\n",
    "        full_obs.append(np.array(list(demos[key]['obs'].values())))\n",
    "        full_act.append(np.array(list(demos[key]['act'].values())))\n",
    "\n",
    "    f.close()\n",
    "\n",
    "# print(len(full_obs), len(full_act))\n",
    "#endregion\n",
    "min_length = 1000\n",
    "for i in range(len(full_obs)):\n",
    "    if len(full_obs[i]) < min_length:\n",
    "        min_length = len(full_obs[i])\n",
    "\n",
    "processed_obs, processed_act = [], []\n",
    "for i in range(len(full_obs)):\n",
    "    processed_obs.append(full_obs[i][np.linspace(0, len(full_obs[i])-1, min_length, dtype=int)])\n",
    "    processed_act.append(full_act[i][np.linspace(0, len(full_obs[i])-1, min_length, dtype=int)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device : cuda:0\n"
     ]
    }
   ],
   "source": [
    "from models.wta_cnp import WTA_CNP\n",
    "import torch\n",
    "\n",
    "def get_available_gpu_with_most_memory():\n",
    "    gpu_memory = []\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        torch.cuda.set_device(i)  # Switch to the GPU to accurately measure memory\n",
    "        gpu_memory.append((i, torch.cuda.memory_stats()['reserved_bytes.all.current'] / (1024 ** 2)))\n",
    "\n",
    "    gpu_memory.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return gpu_memory[0][0]\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    available_gpu = get_available_gpu_with_most_memory()\n",
    "    if available_gpu == 0:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        device = torch.device(f\"cuda:{available_gpu}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device :\", device)\n",
    "\n",
    "###\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: torch.Size([16, 122, 205]) Y: torch.Size([16, 122, 56]) VX: torch.Size([4, 122, 205]) VY: torch.Size([4, 122, 56])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "n_max_obs, n_max_tar = 6, 6\n",
    "\n",
    "t_steps = min_length\n",
    "num_val = 4\n",
    "num_demos = len(full_obs)-num_val\n",
    "num_classes = 2\n",
    "num_indiv = num_demos//num_classes  # number of demos per class\n",
    "\n",
    "dx, dy = len(indices), len(full_act[0][0])\n",
    "\n",
    "num_val_indiv = num_val//num_classes\n",
    "\n",
    "colors = ['tomato', 'aqua']\n",
    "\n",
    "x = torch.zeros(num_demos, t_steps, dx, device=device)\n",
    "y = torch.zeros(num_demos, t_steps, dy, device=device)\n",
    "vx = torch.zeros(num_val, t_steps, dx, device=device)\n",
    "vy = torch.zeros(num_val, t_steps, dy, device=device)\n",
    "\n",
    "ind = torch.randperm(len(full_obs))\n",
    "vind = torch.cat((torch.randint(0, num_indiv, (num_val_indiv, 1)), torch.randint(num_indiv, num_demos, (num_val_indiv, 1))), dim=0)\n",
    "tr_ctr, val_ctr = 0, 0\n",
    "\n",
    "for i in range(len(full_obs)):\n",
    "    if i in vind:\n",
    "        vx[val_ctr] = torch.tensor(processed_obs[i], dtype=torch.float32)\n",
    "        vy[val_ctr] = torch.tensor(processed_act[i], dtype=torch.float32)\n",
    "        val_ctr += 1\n",
    "    else:\n",
    "        x[tr_ctr] = torch.tensor(processed_obs[i], dtype=torch.float32)\n",
    "        y[tr_ctr] = torch.tensor(processed_act[i], dtype=torch.float32)\n",
    "        tr_ctr += 1\n",
    "\n",
    "print(\"X:\", x.shape, \"Y:\", y.shape, \"VX:\", vx.shape, \"VY:\", vy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WTA_CNP(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=261, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (decoders): ModuleList(\n",
       "    (0-1): 2 x Sequential(\n",
       "      (0): Linear(in_features=1229, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=512, out_features=112, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (gate): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=2, bias=True)\n",
       "    (1): Softmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from models.wta_cnp import WTA_CNP\n",
    "\n",
    "root_folder = f'outputs/experimental/56D/1701871167/'\n",
    "wta_model_path = f'{root_folder}saved_models/wta_on_synth.pt'\n",
    "\n",
    "y = torch.load(f'{root_folder}y.pt').cpu()\n",
    "num_samples, t_steps, dy = y.shape\n",
    "dx = 205\n",
    "batch_size = 1\n",
    "n_max_obs, n_max_tar = 6, 6\n",
    "\n",
    "wta = WTA_CNP(dx, dy, n_max_obs, n_max_tar, [1024, 1024, 1024], num_decoders=2, decoder_hidden_dims=[512, 512, 512], batch_size=batch_size, scale_coefs=True).to(device)\n",
    "\n",
    "wta.load_state_dict(torch.load(wta_model_path))\n",
    "wta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import numpy as np\n",
    "import tree\n",
    "import mujoco\n",
    "\n",
    "from typing import Any, Callable, Dict, Optional, Text, Tuple\n",
    "from dm_control import composer\n",
    "from dm_control.locomotion.mocap import cmu_mocap_data\n",
    "from dm_control.locomotion.mocap import loader\n",
    "from dm_control.locomotion.tasks.reference_pose import tracking\n",
    "from dm_control.locomotion.tasks.reference_pose import utils\n",
    "from dm_control.locomotion.walkers import cmu_humanoid\n",
    "from dm_control.locomotion.walkers import initializers\n",
    "\n",
    "class CartwheelInitializer(initializers.WalkerInitializer):\n",
    "    def __init__(self):\n",
    "        ref_path = cmu_mocap_data.get_path_for_cmu(version='2020')\n",
    "        mocap_loader = loader.HDF5TrajectoryLoader(ref_path)\n",
    "        trajectory = mocap_loader.get_trajectory('CMU_049_06')\n",
    "        self._trajectory = trajectory\n",
    "        clip_reference_features = trajectory.as_dict()\n",
    "        clip_reference_features = tracking._strip_reference_prefix(clip_reference_features, 'walker/')\n",
    "        self._cw_features = tree.map_structure(lambda x: x[0], clip_reference_features)\n",
    "\n",
    "    def initialize_pose(self, physics, walker, random_state):\n",
    "        del random_state\n",
    "        utils.set_walker_from_features(physics, walker, self._cw_features)\n",
    "        mujoco.mj_kinematics(physics.model.ptr, physics.data.ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dm_control import viewer\n",
    "from dm_control.locomotion import arenas\n",
    "from dm_control.locomotion.tasks import go_to_target\n",
    "\n",
    "\n",
    "dind = 5\n",
    "\n",
    "def prepare_obs(obs, ind, a):\n",
    "    vv = []\n",
    "    for k in obs.keys():\n",
    "        real_key = k.split('/')[1]\n",
    "        if real_key in desired_observables:\n",
    "            vals = obs[k].flatten()\n",
    "            vv.extend([vals])\n",
    "    if ind == 0:\n",
    "        vv.extend([y[dind, ind].numpy()])\n",
    "    else:\n",
    "        vv.extend([a])\n",
    "    v = np.concatenate(vv).reshape(-1)\n",
    "    return torch.from_numpy(v).view(1, 1, dx+dy).float().to(device)\n",
    "\n",
    "\n",
    "def prepare_tar(ind):\n",
    "    return x[dind, ind].view(1, 1, dx).float().to(device)\n",
    "\n",
    "\n",
    "initializer = CartwheelInitializer()\n",
    "walker = cmu_humanoid.CMUHumanoidPositionControlledV2020(initializer=initializer)\n",
    "arena = arenas.Floor()\n",
    "\n",
    "task = go_to_target.GoToTarget(walker=walker, arena=arena, physics_timestep=0.005, control_timestep=0.03)\n",
    "env = composer.Environment(task=task, random_state=None)\n",
    "# print(env.control_timestep())\n",
    "\n",
    "initializer.initialize_pose(env.physics, walker, None)\n",
    "\n",
    "ind = -1\n",
    "inst_a = None\n",
    "action_spec = env.action_spec()\n",
    "\n",
    "def tst(ts):\n",
    "    global ind, inst_a\n",
    "    ind += 1\n",
    "    dm_obs, dm_tar = prepare_obs(ts.observation, ind, inst_a), prepare_tar(ind+1)\n",
    "    p_wta, g_wta = wta(dm_obs, dm_tar)\n",
    "    # print(g_wta.squeeze(1))\n",
    "    inst_a = p_wta[torch.argmax(g_wta.squeeze(1), dim=-1), 0, 0, :dy].cpu().detach().numpy().squeeze()\n",
    "    return inst_a\n",
    "    # return y[dind, ind].numpy()\n",
    "    # print(env.physics.named.data.body_xpos['torso'].copy())\n",
    "    # action = np.random.uniform(action_spec.minimum, action_spec.maximum, size=action_spec.shape)\n",
    "    # return action\n",
    "\n",
    "# Viewer for visualization\n",
    "viewer.launch(env, policy=tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dm_control.locomotion.mocap.trajectory.Trajectory at 0x7ff7e0ee50a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initializer._trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
