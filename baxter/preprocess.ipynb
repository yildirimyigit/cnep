{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from conv_autoenc import ConvAE\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = '1717378265'\n",
    "\n",
    "model = ConvAE(filter_sizes=[2048,1536,1024,512]).to(device)\n",
    "model.load_state_dict(torch.load(f'output/ae/{run_id}/saved_model/best_cae.pt', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "try:\n",
    "    os.makedirs('processed')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_steps = 400\n",
    "\n",
    "def crop_left(im): \n",
    "    return transforms.functional.crop(im, top=0, left=0, height=420, width=560)\n",
    "\n",
    "img_tf = transforms.Compose([\n",
    "    transforms.Lambda(crop_left),  # Crop the left side\n",
    "    transforms.Lambda(lambda x: x.convert('RGB')),  # Ensure the image is in RGB mode\n",
    "    transforms.Resize(size=(128, 96), antialias=True),  # Downsample to 128xH\n",
    "    transforms.Pad(padding=(16, 0, 16, 0)), # Pad to 128x128\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to range [-1, 1]\n",
    "])\n",
    "\n",
    "for i in range(24):\n",
    "    data_folder = f'/home/yigit/projects/cnep/baxter/data/ral/{i}/'\n",
    "    # iterate over all files in the in_folder\n",
    "    for filename in os.listdir(data_folder):\n",
    "        d = os.path.join(data_folder, filename)\n",
    "        if filename.endswith('.jpeg'):\n",
    "            img = img_tf(Image.open(d))\n",
    "            with torch.no_grad():\n",
    "                encoding = model.encode(img)\n",
    "                torch.save(data, f\"processed/enc_{i}.pt\")\n",
    "\n",
    "        if filename.endswith('.csv'):\n",
    "            temp_data = []\n",
    "            with open(d, 'r') as f:\n",
    "                for j, line in enumerate(csv.reader(f)):\n",
    "                    if j > 0:\n",
    "                        temp_data.append([float(line[3]), float(line[4]), float(line[5]), float(line[6]), float(line[7]), float(line[8]), float(line[9]), float(line[10])])  # p, q, gripper\n",
    "\n",
    "            ids = torch.linspace(0, len(temp_data)-1, t_steps).int().tolist()\n",
    "            data = torch.tensor([temp_data[i] for i in ids])\n",
    "            torch.save(data, f\"processed/traj_{i}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
