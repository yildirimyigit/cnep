{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device : cuda:0\n"
     ]
    }
   ],
   "source": [
    "from models.cnep import CNEP\n",
    "\n",
    "from data.data_generators import *\n",
    "import torch\n",
    "\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "def get_free_gpu():\n",
    "    gpu_util = []\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        torch.cuda.set_device(i)  # Switch GPU\n",
    "        gpu_util.append((i, torch.cuda.utilization()))\n",
    "    gpu_util.sort(key=lambda x: x[1])\n",
    "    return gpu_util[0][0]\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    available_gpu = get_free_gpu()\n",
    "    if available_gpu == 0:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        device = torch.device(f\"cuda:{available_gpu}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device :\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_max, m_max = 6, 6  # max number of points in context set and target set\n",
    "\n",
    "t_steps = 200\n",
    "num_demos = 128\n",
    "num_classes = 2\n",
    "num_indiv = num_demos//num_classes  # number of demos per class\n",
    "noise_clip = 0.0\n",
    "dx, dy = 1, 1\n",
    "\n",
    "num_val = 32\n",
    "num_val_indiv = num_val//num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: torch.Size([128, 200, 1]) Y: torch.Size([128, 200, 1]) VX: torch.Size([32, 200, 1]) VY: torch.Size([32, 200, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.linspace(0, 1, 200).repeat(num_demos, 1).unsqueeze(-1)\n",
    "vx = torch.linspace(0, 1, 200).repeat(num_val, 1).unsqueeze(-1)\n",
    "y = torch.zeros((num_demos, x.shape[1], 1))\n",
    "vy = torch.zeros((num_val, vx.shape[1], 1))\n",
    "\n",
    "frequencies = [1, 2.5, 4, 5.5]  # Example frequencies\n",
    "amplitudes = [1.5, 1, 0.8, 0.6]  # Example amplitudes\n",
    "phases = [0, torch.pi / 2, torch.pi, 3 * torch.pi / 2]  # Example phases\n",
    "\n",
    "\n",
    "for i in range(num_demos):\n",
    "    y[i, :, 0] = amplitudes[i%2] * torch.sin(2 * torch.pi * frequencies[i%2] * x[i, :, 0] + phases[i%2]) + torch.randn(1) * 0.05\n",
    "for i in range(num_val):\n",
    "    vy[i, :, 0] = amplitudes[i%2] * torch.sin(2 * torch.pi * frequencies[i%2] * vx[i, :, 0] + phases[i%2]) + torch.randn(1) * 0.05\n",
    "\n",
    "print(\"X:\", x.shape, \"Y:\", y.shape, \"VX:\", vx.shape, \"VY:\", vy.shape)\n",
    "x, y, vx, vy = x.to(device), y.to(device), vx.to(device), vy.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = torch.zeros((batch_size, n_max, dx+dy), dtype=torch.float32, device=device)\n",
    "tar_x = torch.zeros((batch_size, m_max, dx), dtype=torch.float32, device=device)\n",
    "tar_y = torch.zeros((batch_size, m_max, dy), dtype=torch.float32, device=device)\n",
    "obs_mask = torch.zeros((batch_size, n_max), dtype=torch.bool, device=device)\n",
    "tar_mask = torch.zeros((batch_size, m_max), dtype=torch.bool, device=device)\n",
    "\n",
    "def prepare_masked_batch(t: list, traj_ids: list):\n",
    "    obs.fill_(0)\n",
    "    tar_x.fill_(0)\n",
    "    tar_y.fill_(0)\n",
    "    obs_mask.fill_(False)\n",
    "    tar_mask.fill_(False)\n",
    "\n",
    "    for i, traj_id in enumerate(traj_ids):\n",
    "        traj = t[traj_id]\n",
    "\n",
    "        n = torch.randint(1, n_max, (1,)).item()\n",
    "        m = torch.randint(1, m_max, (1,)).item()\n",
    "\n",
    "        permuted_ids = torch.randperm(t_steps)\n",
    "        n_ids = permuted_ids[:n]\n",
    "        m_ids = permuted_ids[n:n+m]\n",
    "        \n",
    "        obs[i, :n, :dx] = (n_ids/t_steps).unsqueeze(1)\n",
    "        obs[i, :n, dx:] = traj[n_ids]\n",
    "        obs_mask[i, :n] = True\n",
    "        \n",
    "        tar_x[i, :m] = (m_ids/t_steps).unsqueeze(1)\n",
    "        tar_y[i, :m] = traj[m_ids]\n",
    "        tar_mask[i, :m] = True\n",
    "\n",
    "val_obs = torch.zeros((batch_size, n_max, dx+dy), dtype=torch.float32, device=device)\n",
    "val_tar_x = torch.zeros((batch_size, t_steps, dx), dtype=torch.float32, device=device)\n",
    "val_tar_y = torch.zeros((batch_size, t_steps, dy), dtype=torch.float32, device=device)\n",
    "val_obs_mask = torch.zeros((batch_size, n_max), dtype=torch.bool, device=device)\n",
    "\n",
    "def prepare_masked_val_batch(t: list, traj_ids: list):\n",
    "    val_obs.fill_(0)\n",
    "    val_tar_x.fill_(0)\n",
    "    val_tar_y.fill_(0)\n",
    "    val_obs_mask.fill_(False)\n",
    "\n",
    "    for i, traj_id in enumerate(traj_ids):\n",
    "        traj = t[traj_id]\n",
    "\n",
    "        n = torch.randint(1, n_max, (1,)).item()\n",
    "\n",
    "        permuted_ids = torch.randperm(t_steps)\n",
    "        n_ids = permuted_ids[:n]\n",
    "        m_ids = torch.arange(t_steps)\n",
    "        \n",
    "        val_obs[i, :n, :dx] = (n_ids/t_steps).unsqueeze(1)\n",
    "        val_obs[i, :n, dx:] = traj[n_ids]\n",
    "        val_obs_mask[i, :n] = True\n",
    "        \n",
    "        val_tar_x[i] = (m_ids/t_steps).unsqueeze(1)\n",
    "        val_tar_y[i] = traj[m_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnep2: 50950\n",
      "cnep4: 51212\n",
      "cnep8: 51736\n"
     ]
    }
   ],
   "source": [
    "model2_ = CNEP(1, 1, n_max, n_max, [128,128], num_decoders=2, decoder_hidden_dims=[128, 128], batch_size=batch_size, scale_coefs=True, device=device)\n",
    "optimizer2 = torch.optim.Adam(lr=3e-4, params=model2_.parameters())\n",
    "\n",
    "model4_ = CNEP(1, 1, n_max, n_max, [128,128], num_decoders=4, decoder_hidden_dims=[64, 64], batch_size=batch_size, scale_coefs=True, device=device)\n",
    "optimizer4 = torch.optim.Adam(lr=3e-4, params=model4_.parameters())\n",
    "\n",
    "model8_ = CNEP(1, 1, n_max, n_max, [128,128], num_decoders=8, decoder_hidden_dims=[32, 32], batch_size=batch_size, scale_coefs=True, device=device)\n",
    "optimizer8 = torch.optim.Adam(lr=3e-4, params=model8_.parameters())\n",
    "\n",
    "def get_parameter_count(model):\n",
    "    total_num = 0\n",
    "    for param in model.parameters():\n",
    "        total_num += param.shape.numel()\n",
    "    return total_num\n",
    "\n",
    "print(\"cnep2:\", get_parameter_count(model2_))\n",
    "print(\"cnep4:\", get_parameter_count(model4_))\n",
    "print(\"cnep8:\", get_parameter_count(model8_))\n",
    "\n",
    "if torch.__version__ >= \"2.0\":\n",
    "    model2, model4, model8 = torch.compile(model2_), torch.compile(model4_), torch.compile(model8_)\n",
    "else:\n",
    "    model2, model4, model8 = model2_, model4_, model8_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best 2: 0.8212732672691345\n",
      "New best 4: 0.8140174746513367\n",
      "New best 8: 0.8189805150032043\n",
      "Bests: 0.8212732672691345, 0.8140174746513367, 0.8189805150032043\n",
      "Epoch: 0, CNEP Losses: 0.00014180809557437897, 7.083806544542313e-05, 3.626886829733849e-05\n",
      "New best 2: 0.3458179533481598\n",
      "New best 4: 0.48303985595703125\n",
      "New best 8: 0.49350377917289734\n",
      "Bests: 0.3458179533481598, 0.48303985595703125, 0.49350377917289734\n",
      "Epoch: 5000, CNEP Losses: 0.48248271871805193, 0.27120593912899493, 0.13484154193848372\n",
      "New best 2: 0.1381293535232544\n",
      "New best 4: 0.24772578477859497\n",
      "New best 8: 0.29477787017822266\n",
      "Bests: 0.1381293535232544, 0.24772578477859497, 0.29477787017822266\n",
      "Epoch: 10000, CNEP Losses: 0.008912811569450424, 0.1419747181772138, 0.06518963374147424\n",
      "New best 2: 0.1321202516555786\n",
      "New best 4: 0.22614482045173645\n",
      "Bests: 0.1321202516555786, 0.22614482045173645, 0.29477787017822266\n",
      "Epoch: 15000, CNEP Losses: -0.3227918337549083, -0.027258398354321253, 0.025801175794453592\n",
      "New best 2: 0.09667787700891495\n",
      "Bests: 0.09667787700891495, 0.22614482045173645, 0.29477787017822266\n",
      "Epoch: 20000, CNEP Losses: -0.5095229831187986, -0.07611451816189801, 0.0058121503415110055\n",
      "New best 2: 0.011229949072003365\n",
      "New best 8: 0.2376837432384491\n",
      "Bests: 0.011229949072003365, 0.22614482045173645, 0.2376837432384491\n",
      "Epoch: 25000, CNEP Losses: -0.5901390648468398, -0.11033391489542554, -0.00721080862818053\n",
      "New best 4: 0.2005724310874939\n",
      "Bests: 0.011229949072003365, 0.2005724310874939, 0.2376837432384491\n",
      "Epoch: 30000, CNEP Losses: -0.6620827515288256, -0.13920627809627914, -0.02126254231320927\n",
      "Bests: 0.011229949072003365, 0.2005724310874939, 0.2376837432384491\n",
      "Epoch: 35000, CNEP Losses: -0.7216508973226883, -0.16452895881214644, -0.03654424272860633\n",
      "New best 8: 0.20772512257099152\n",
      "Bests: 0.011229949072003365, 0.2005724310874939, 0.20772512257099152\n",
      "Epoch: 40000, CNEP Losses: -0.7706030135509092, -0.19167318258368177, -0.04800290694970172\n",
      "New best 4: 0.14532075822353363\n",
      "New best 8: 0.19730952382087708\n",
      "Bests: 0.011229949072003365, 0.14532075822353363, 0.19730952382087708\n",
      "Epoch: 45000, CNEP Losses: -0.821056461439468, -0.2084009242018219, -0.05855597347442526\n",
      "New best 4: 0.10995412617921829\n",
      "New best 8: 0.1435387134552002\n",
      "Bests: 0.011229949072003365, 0.10995412617921829, 0.1435387134552002\n",
      "Epoch: 50000, CNEP Losses: -0.8667088447693735, -0.23758691843771376, -0.06754001817126991\n",
      "Bests: 0.011229949072003365, 0.10995412617921829, 0.1435387134552002\n",
      "Epoch: 55000, CNEP Losses: -0.9046742745506111, -0.2636036960569676, -0.07410450334626949\n",
      "New best 4: 0.09675776213407516\n",
      "New best 8: 0.11725278943777084\n",
      "Bests: 0.011229949072003365, 0.09675776213407516, 0.11725278943777084\n",
      "Epoch: 60000, CNEP Losses: -0.8906594577768817, -0.28887826499603686, -0.08269879627618938\n",
      "New best 4: 0.08185102045536041\n",
      "Bests: 0.011229949072003365, 0.08185102045536041, 0.11725278943777084\n",
      "Epoch: 65000, CNEP Losses: -0.9071274971774779, -0.3132080179071054, -0.09131942323953844\n",
      "New best 8: 0.08244527876377106\n",
      "Bests: 0.011229949072003365, 0.08185102045536041, 0.08244527876377106\n",
      "Epoch: 70000, CNEP Losses: -0.9563221242598258, -0.33285916711208413, -0.1043494643049431\n",
      "New best 4: 0.03539278730750084\n",
      "Bests: 0.011229949072003365, 0.03539278730750084, 0.08244527876377106\n",
      "Epoch: 75000, CNEP Losses: -0.9494727490112186, -0.3518689889967442, -0.12110242297926452\n",
      "New best 8: 0.049182917922735214\n",
      "Bests: 0.011229949072003365, 0.03539278730750084, 0.049182917922735214\n",
      "Epoch: 80000, CNEP Losses: -0.9283555909048766, -0.36710421955138445, -0.13852974108082708\n",
      "New best 8: 0.023641841486096382\n",
      "Bests: 0.011229949072003365, 0.03539278730750084, 0.023641841486096382\n",
      "Epoch: 85000, CNEP Losses: -1.014348174692504, -0.37918804304124787, -0.1533014903109288\n",
      "Bests: 0.011229949072003365, 0.03539278730750084, 0.023641841486096382\n",
      "Epoch: 90000, CNEP Losses: -0.9885537513749674, -0.3936735824414529, -0.1645690103236586\n",
      "New best 8: 0.0048361485823988914\n",
      "Bests: 0.011229949072003365, 0.03539278730750084, 0.0048361485823988914\n",
      "Epoch: 95000, CNEP Losses: -1.0020299745243042, -0.4057449058723636, -0.16786164454321842\n",
      "Bests: 0.011229949072003365, 0.03539278730750084, 0.0048361485823988914\n",
      "Epoch: 100000, CNEP Losses: -1.0395586180420593, -0.4195394934162963, -0.17589271698566153\n",
      "Bests: 0.011229949072003365, 0.03539278730750084, 0.0048361485823988914\n",
      "Epoch: 105000, CNEP Losses: -1.0924477810621263, -0.431298150378, -0.1766962819550652\n",
      "New best 2: 0.0015527905197814107\n",
      "New best 4: 0.01761552505195141\n",
      "Bests: 0.0015527905197814107, 0.01761552505195141, 0.0048361485823988914\n",
      "Epoch: 110000, CNEP Losses: -1.1009328451516107, -0.44735998442401176, -0.18082390435587148\n",
      "Bests: 0.0015527905197814107, 0.01761552505195141, 0.0048361485823988914\n",
      "Epoch: 115000, CNEP Losses: -1.086266520961281, -0.45082558254031463, -0.18178510909220202\n",
      "New best 2: 0.0007575565250590444\n",
      "New best 4: 0.008338655345141888\n",
      "New best 8: 0.004024378955364227\n",
      "Bests: 0.0007575565250590444, 0.008338655345141888, 0.004024378955364227\n",
      "Epoch: 120000, CNEP Losses: -1.0915141961302608, -0.4680078915975988, -0.18564750705203042\n",
      "Bests: 0.0007575565250590444, 0.008338655345141888, 0.004024378955364227\n",
      "Epoch: 125000, CNEP Losses: -1.109522707081586, -0.4833226074115373, -0.1902813020297792\n",
      "Bests: 0.0007575565250590444, 0.008338655345141888, 0.004024378955364227\n",
      "Epoch: 130000, CNEP Losses: -1.1299012989399955, -0.4896194445169531, -0.1946044844652526\n",
      "Bests: 0.0007575565250590444, 0.008338655345141888, 0.004024378955364227\n",
      "Epoch: 135000, CNEP Losses: -1.147901482633315, -0.4981514593500178, -0.19490998097513804\n",
      "Bests: 0.0007575565250590444, 0.008338655345141888, 0.004024378955364227\n",
      "Epoch: 140000, CNEP Losses: -1.1416930972287431, -0.4963133782921359, -0.1962301087019965\n",
      "Bests: 0.0007575565250590444, 0.008338655345141888, 0.004024378955364227\n",
      "Epoch: 145000, CNEP Losses: -1.1350457361501642, -0.508398149102088, -0.19993146653184668\n",
      "New best 4: 0.0012769382447004318\n",
      "Bests: 0.0007575565250590444, 0.0012769382447004318, 0.004024378955364227\n",
      "Epoch: 150000, CNEP Losses: -1.1761396590396762, -0.5052307703974657, -0.19960047346279025\n",
      "Bests: 0.0007575565250590444, 0.0012769382447004318, 0.004024378955364227\n",
      "Epoch: 155000, CNEP Losses: -1.143812242623791, -0.5089388028582558, -0.20309666095254944\n",
      "New best 4: 0.000959680590312928\n",
      "Bests: 0.0007575565250590444, 0.000959680590312928, 0.004024378955364227\n",
      "Epoch: 160000, CNEP Losses: -1.1620019700642674, -0.5145987685160711, -0.19667445160730276\n",
      "Bests: 0.0007575565250590444, 0.000959680590312928, 0.004024378955364227\n",
      "Epoch: 165000, CNEP Losses: -1.203456860601902, -0.5015110742895398, -0.20965704175787978\n",
      "Bests: 0.0007575565250590444, 0.000959680590312928, 0.004024378955364227\n",
      "Epoch: 170000, CNEP Losses: -1.212239527970925, -0.5225630205237307, -0.20688955444712193\n",
      "Bests: 0.0007575565250590444, 0.000959680590312928, 0.004024378955364227\n",
      "Epoch: 175000, CNEP Losses: -1.1990746139097028, -0.5224401995311025, -0.19713948687927332\n",
      "Bests: 0.0007575565250590444, 0.000959680590312928, 0.004024378955364227\n",
      "Epoch: 180000, CNEP Losses: -1.1945248761683702, -0.5285847566934302, -0.19735370044918965\n",
      "Bests: 0.0007575565250590444, 0.000959680590312928, 0.004024378955364227\n",
      "Epoch: 185000, CNEP Losses: -1.2130225639486685, -0.5255126511754468, -0.20388603993905707\n",
      "Bests: 0.0007575565250590444, 0.000959680590312928, 0.004024378955364227\n",
      "Epoch: 190000, CNEP Losses: -1.1719404753753915, -0.5365682894543745, -0.21231597153479234\n",
      "Bests: 0.0007575565250590444, 0.000959680590312928, 0.004024378955364227\n",
      "Epoch: 195000, CNEP Losses: -1.1830318536369595, -0.5478176884215326, -0.21560101672585588\n",
      "Bests: 0.0007575565250590444, 0.000959680590312928, 0.004024378955364227\n",
      "Epoch: 200000, CNEP Losses: -1.108071043771971, -0.5472148356307298, -0.21674951190785505\n",
      "Bests: 0.0007575565250590444, 0.000959680590312928, 0.004024378955364227\n",
      "Epoch: 205000, CNEP Losses: -1.2278151146929712, -0.5504989072723314, -0.21856801156601868\n",
      "Bests: 0.0007575565250590444, 0.000959680590312928, 0.004024378955364227\n",
      "Epoch: 210000, CNEP Losses: -1.229247654066235, -0.5464581873485819, -0.2238172137054149\n",
      "Bests: 0.0007575565250590444, 0.000959680590312928, 0.004024378955364227\n",
      "Epoch: 215000, CNEP Losses: -1.2463172462651506, -0.5609543643075973, -0.21169733556483405\n",
      "New best 2: 0.000418825657106936\n",
      "Bests: 0.000418825657106936, 0.000959680590312928, 0.004024378955364227\n",
      "Epoch: 220000, CNEP Losses: -1.237921410470549, -0.5581700657473877, -0.22239771844600328\n",
      "New best 8: 0.003728559473529458\n",
      "Bests: 0.000418825657106936, 0.000959680590312928, 0.003728559473529458\n",
      "Epoch: 225000, CNEP Losses: -1.2536567261666058, -0.5572197974450886, -0.22075470483778045\n",
      "Bests: 0.000418825657106936, 0.000959680590312928, 0.003728559473529458\n",
      "Epoch: 230000, CNEP Losses: -1.2362766758471728, -0.5310030256547965, -0.22205483147555496\n",
      "Bests: 0.000418825657106936, 0.000959680590312928, 0.003728559473529458\n",
      "Epoch: 235000, CNEP Losses: -1.2407382751125842, -0.5562418434204534, -0.22250378830467815\n",
      "New best 2: 0.00027258851332589984\n",
      "Bests: 0.00027258851332589984, 0.000959680590312928, 0.003728559473529458\n",
      "Epoch: 240000, CNEP Losses: -1.2401912343896926, -0.5707053686272353, -0.2269703296159394\n",
      "Bests: 0.00027258851332589984, 0.000959680590312928, 0.003728559473529458\n",
      "Epoch: 245000, CNEP Losses: -1.1907821396143177, -0.5613787837404758, -0.22232833314905875\n",
      "Bests: 0.00027258851332589984, 0.000959680590312928, 0.003728559473529458\n",
      "Epoch: 250000, CNEP Losses: -1.263141258714348, -0.5547027117189951, -0.2251562258562539\n",
      "Bests: 0.00027258851332589984, 0.000959680590312928, 0.003728559473529458\n",
      "Epoch: 255000, CNEP Losses: -1.1973450277007651, -0.5638505032649264, -0.22233871531989424\n",
      "Bests: 0.00027258851332589984, 0.000959680590312928, 0.003728559473529458\n",
      "Epoch: 260000, CNEP Losses: -1.2339946172706784, -0.5481541626635938, -0.22898191274860874\n",
      "Bests: 0.00027258851332589984, 0.000959680590312928, 0.003728559473529458\n",
      "Epoch: 265000, CNEP Losses: -1.2576585189016536, -0.5700934627841227, -0.22345931638982147\n",
      "Bests: 0.00027258851332589984, 0.000959680590312928, 0.003728559473529458\n",
      "Epoch: 270000, CNEP Losses: -1.2653732349501923, -0.5715808113232255, -0.21858731083162128\n",
      "Bests: 0.00027258851332589984, 0.000959680590312928, 0.003728559473529458\n",
      "Epoch: 275000, CNEP Losses: -1.290541400871612, -0.5604715537318028, -0.22545244045432192\n",
      "New best 2: 0.00026192967197857797\n",
      "Bests: 0.00026192967197857797, 0.000959680590312928, 0.003728559473529458\n",
      "Epoch: 280000, CNEP Losses: -1.3106999535277486, -0.583749322926253, -0.2263152039701119\n",
      "Bests: 0.00026192967197857797, 0.000959680590312928, 0.003728559473529458\n",
      "Epoch: 285000, CNEP Losses: -1.2513080469749869, -0.5818595554433763, -0.225087780509796\n",
      "New best 4: 0.0008974824449978769\n",
      "Bests: 0.00026192967197857797, 0.0008974824449978769, 0.003728559473529458\n",
      "Epoch: 290000, CNEP Losses: -1.2330105088680983, -0.5767914942105301, -0.2225360344108194\n",
      "Bests: 0.00026192967197857797, 0.0008974824449978769, 0.003728559473529458\n",
      "Epoch: 295000, CNEP Losses: -1.282000862839492, -0.5835707833833061, -0.22065534039724152\n",
      "New best 4: 0.00072516780346632\n",
      "Bests: 0.00026192967197857797, 0.00072516780346632, 0.003728559473529458\n",
      "Epoch: 300000, CNEP Losses: -1.2785497685089708, -0.5678118194233626, -0.22741908345427364\n",
      "New best 8: 0.002875237027183175\n",
      "Bests: 0.00026192967197857797, 0.00072516780346632, 0.002875237027183175\n",
      "Epoch: 305000, CNEP Losses: -1.2982122818684205, -0.5847828506622463, -0.22909730630132835\n",
      "Bests: 0.00026192967197857797, 0.00072516780346632, 0.002875237027183175\n",
      "Epoch: 310000, CNEP Losses: -1.331071761830151, -0.5669986463563983, -0.23348589499040973\n",
      "New best 2: 0.00022323276789393276\n",
      "New best 8: 0.0027908708434551954\n",
      "Bests: 0.00022323276789393276, 0.00072516780346632, 0.0027908708434551954\n",
      "Epoch: 315000, CNEP Losses: -1.346028585215658, -0.5857583725973964, -0.23295619782884605\n",
      "Bests: 0.00022323276789393276, 0.00072516780346632, 0.0027908708434551954\n",
      "Epoch: 320000, CNEP Losses: -1.287290943516232, -0.5805191970122978, -0.23204195345088374\n",
      "Bests: 0.00022323276789393276, 0.00072516780346632, 0.0027908708434551954\n",
      "Epoch: 325000, CNEP Losses: -1.3278686671197415, -0.5920931388957426, -0.238067653694842\n",
      "Bests: 0.00022323276789393276, 0.00072516780346632, 0.0027908708434551954\n",
      "Epoch: 330000, CNEP Losses: -1.3581994857542217, -0.5863056210055015, -0.2359013039725367\n",
      "Bests: 0.00022323276789393276, 0.00072516780346632, 0.0027908708434551954\n",
      "Epoch: 335000, CNEP Losses: -1.3153488598590717, -0.5885286695996299, -0.2385372688539792\n",
      "Bests: 0.00022323276789393276, 0.00072516780346632, 0.0027908708434551954\n",
      "Epoch: 340000, CNEP Losses: -1.3407422150727362, -0.591654013876617, -0.23554146840027534\n",
      "Bests: 0.00022323276789393276, 0.00072516780346632, 0.0027908708434551954\n",
      "Epoch: 345000, CNEP Losses: -1.2959327322039753, -0.6042182553127408, -0.23222396783402655\n",
      "Bests: 0.00022323276789393276, 0.00072516780346632, 0.0027908708434551954\n",
      "Epoch: 350000, CNEP Losses: -1.3035200313415378, -0.6005986763639841, -0.23801103609995916\n",
      "Bests: 0.00022323276789393276, 0.00072516780346632, 0.0027908708434551954\n",
      "Epoch: 355000, CNEP Losses: -1.3687444924943148, -0.6068338757559657, -0.23815890609137713\n",
      "Bests: 0.00022323276789393276, 0.00072516780346632, 0.0027908708434551954\n",
      "Epoch: 360000, CNEP Losses: -1.3572547347871586, -0.6070822186093312, -0.23959703556909226\n",
      "New best 2: 0.0001789128000382334\n",
      "Bests: 0.0001789128000382334, 0.00072516780346632, 0.0027908708434551954\n",
      "Epoch: 365000, CNEP Losses: -1.3765884025633335, -0.5859593491047621, -0.24192046521725133\n",
      "Bests: 0.0001789128000382334, 0.00072516780346632, 0.0027908708434551954\n",
      "Epoch: 370000, CNEP Losses: -1.3138065331235529, -0.6080273314770311, -0.23567223980156704\n",
      "New best 8: 0.0027183156926184893\n",
      "Bests: 0.0001789128000382334, 0.00072516780346632, 0.0027183156926184893\n",
      "Epoch: 375000, CNEP Losses: -1.2385072167538107, -0.6282131374560297, -0.24436505232206546\n",
      "Bests: 0.0001789128000382334, 0.00072516780346632, 0.0027183156926184893\n",
      "Epoch: 380000, CNEP Losses: -1.364190797006339, -0.6144730099610053, -0.24034445265238175\n",
      "New best 4: 0.0005847381544299424\n",
      "New best 8: 0.0026666356716305017\n",
      "Bests: 0.0001789128000382334, 0.0005847381544299424, 0.0026666356716305017\n",
      "Epoch: 385000, CNEP Losses: -1.342318879206106, -0.6299870890185237, -0.24112905767876655\n",
      "New best 8: 0.002639632672071457\n",
      "Bests: 0.0001789128000382334, 0.0005847381544299424, 0.002639632672071457\n",
      "Epoch: 390000, CNEP Losses: -1.3546084277674555, -0.6172131780909375, -0.24236633788417095\n",
      "Bests: 0.0001789128000382334, 0.0005847381544299424, 0.002639632672071457\n",
      "Epoch: 395000, CNEP Losses: -1.3382297519620507, -0.6354516201604158, -0.24730478453412652\n",
      "Bests: 0.0001789128000382334, 0.0005847381544299424, 0.002639632672071457\n",
      "Epoch: 400000, CNEP Losses: -1.3802075017709285, -0.6158994902587496, -0.23966775479519273\n",
      "Bests: 0.0001789128000382334, 0.0005847381544299424, 0.002639632672071457\n",
      "Epoch: 405000, CNEP Losses: -1.3771700458556413, -0.6274110088368412, -0.240793239218893\n",
      "Bests: 0.0001789128000382334, 0.0005847381544299424, 0.002639632672071457\n",
      "Epoch: 410000, CNEP Losses: -1.3959082168109715, -0.6276094379769638, -0.24387253796318545\n",
      "New best 8: 0.002499958500266075\n",
      "Bests: 0.0001789128000382334, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 415000, CNEP Losses: -1.4115409231759608, -0.6367253205168992, -0.23158881539262366\n",
      "New best 2: 0.00016743945889174938\n",
      "Bests: 0.00016743945889174938, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 420000, CNEP Losses: -1.366412351379171, -0.6243650134344585, -0.2421185581624508\n",
      "Bests: 0.00016743945889174938, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 425000, CNEP Losses: -1.3925320770524443, -0.6175205181591212, -0.24274566181823612\n",
      "New best 2: 0.00015952963440213352\n",
      "Bests: 0.00015952963440213352, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 430000, CNEP Losses: -1.3393827024001628, -0.6165040293273516, -0.2418494203193928\n",
      "Bests: 0.00015952963440213352, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 435000, CNEP Losses: -1.3513265300506725, -0.6238876983966678, -0.243678525592573\n",
      "Bests: 0.00015952963440213352, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 440000, CNEP Losses: -1.380918473258242, -0.6211363040631637, -0.24343598850425333\n",
      "Bests: 0.00015952963440213352, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 445000, CNEP Losses: -1.399816111409664, -0.6384365916038863, -0.2488498334423639\n",
      "Bests: 0.00015952963440213352, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 450000, CNEP Losses: -1.402374785521999, -0.639851084960159, -0.2483864274681546\n",
      "Bests: 0.00015952963440213352, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 455000, CNEP Losses: -1.3372204495694489, -0.638270316156838, -0.24800761804874055\n",
      "Bests: 0.00015952963440213352, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 460000, CNEP Losses: -1.3299487780399621, -0.5900203658043407, -0.24937934817085042\n",
      "Bests: 0.00015952963440213352, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 465000, CNEP Losses: -1.379116317698639, -0.6257513573888689, -0.25067367876982316\n",
      "Bests: 0.00015952963440213352, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 470000, CNEP Losses: -1.3739555166706443, -0.628624221464619, -0.24740757484366185\n",
      "Bests: 0.00015952963440213352, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 475000, CNEP Losses: -1.3799768962416799, -0.641324880384095, -0.2507309783888049\n",
      "Bests: 0.00015952963440213352, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 480000, CNEP Losses: -1.408028362984769, -0.6408521336169913, -0.25308864363636824\n",
      "Bests: 0.00015952963440213352, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 485000, CNEP Losses: -1.4267157185215502, -0.628152644089982, -0.25445227051861585\n",
      "Bests: 0.00015952963440213352, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 490000, CNEP Losses: -1.4435552885606886, -0.6419233514801599, -0.25378364221798255\n",
      "Bests: 0.00015952963440213352, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 495000, CNEP Losses: -1.3639005148351193, -0.6474931117658503, -0.24877919830074532\n",
      "Bests: 0.00015952963440213352, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 500000, CNEP Losses: -1.4395559784814715, -0.6434455003146082, -0.24980884957588279\n",
      "New best 2: 0.00015460130816791207\n",
      "Bests: 0.00015460130816791207, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 505000, CNEP Losses: -1.4518393942311407, -0.6376278356129303, -0.24942670059427619\n",
      "Bests: 0.00015460130816791207, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 510000, CNEP Losses: -1.3654768043376506, -0.6297157877753489, -0.2553463351799175\n",
      "Bests: 0.00015460130816791207, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 515000, CNEP Losses: -1.3816683060728014, -0.6360858326791786, -0.2544268388721626\n",
      "Bests: 0.00015460130816791207, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 520000, CNEP Losses: -1.427986656018719, -0.5926310518950689, -0.25479845697479325\n",
      "Bests: 0.00015460130816791207, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 525000, CNEP Losses: -1.3215987920279615, -0.6359120238142089, -0.2543216650557704\n",
      "New best 2: 0.00012993838754482567\n",
      "Bests: 0.00012993838754482567, 0.0005847381544299424, 0.002499958500266075\n",
      "Epoch: 530000, CNEP Losses: -1.3460807091284543, -0.6380785757482051, -0.2517310528258793\n",
      "New best 4: 0.000539949513040483\n",
      "Bests: 0.00012993838754482567, 0.000539949513040483, 0.002499958500266075\n",
      "Epoch: 535000, CNEP Losses: -1.3871315320312976, -0.6432303330985829, -0.25356873206407765\n",
      "Bests: 0.00012993838754482567, 0.000539949513040483, 0.002499958500266075\n",
      "Epoch: 540000, CNEP Losses: -1.3938955000625923, -0.6309732349162921, -0.2519777460674755\n",
      "Bests: 0.00012993838754482567, 0.000539949513040483, 0.002499958500266075\n",
      "Epoch: 545000, CNEP Losses: -1.4436850801043213, -0.6399151521246881, -0.25474818314444275\n",
      "Bests: 0.00012993838754482567, 0.000539949513040483, 0.002499958500266075\n",
      "Epoch: 550000, CNEP Losses: -1.3390271038983017, -0.6362788881003857, -0.25810582279087974\n",
      "Bests: 0.00012993838754482567, 0.000539949513040483, 0.002499958500266075\n",
      "Epoch: 555000, CNEP Losses: -1.3470643332906067, -0.6469055765187368, -0.25946255785443356\n",
      "Bests: 0.00012993838754482567, 0.000539949513040483, 0.002499958500266075\n",
      "Epoch: 560000, CNEP Losses: -1.4281277230970562, -0.6528755515523255, -0.2576228477929719\n",
      "Bests: 0.00012993838754482567, 0.000539949513040483, 0.002499958500266075\n",
      "Epoch: 565000, CNEP Losses: -1.3965421798326074, -0.6513979535117745, -0.2507926910409704\n",
      "New best 2: 9.907743515213951e-05\n",
      "Bests: 9.907743515213951e-05, 0.000539949513040483, 0.002499958500266075\n",
      "Epoch: 570000, CNEP Losses: -1.4351907044608145, -0.63832436233107, -0.2487604084921535\n",
      "Bests: 9.907743515213951e-05, 0.000539949513040483, 0.002499958500266075\n",
      "Epoch: 575000, CNEP Losses: -1.3106321428675205, -0.6005900248364545, -0.24945815528267995\n",
      "New best 4: 0.0005071411142125726\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.002499958500266075\n",
      "Epoch: 580000, CNEP Losses: -1.4050453315138818, -0.651522580993548, -0.2569890671909787\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.002499958500266075\n",
      "Epoch: 585000, CNEP Losses: -1.4255083038519136, -0.6271025435362011, -0.2582178951452486\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.002499958500266075\n",
      "Epoch: 590000, CNEP Losses: -1.3545078042410315, -0.6486931842915714, -0.256608626856748\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.002499958500266075\n",
      "Epoch: 595000, CNEP Losses: -1.3660972129251807, -0.6487774853162468, -0.25653213589293883\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.002499958500266075\n",
      "Epoch: 600000, CNEP Losses: -1.4507229354567825, -0.6525124053612351, -0.25752087797839196\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.002499958500266075\n",
      "Epoch: 605000, CNEP Losses: -1.4498586197897791, -0.6360183377895504, -0.25379685459560714\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.002499958500266075\n",
      "Epoch: 610000, CNEP Losses: -1.4502475413251668, -0.6532268288051709, -0.26114825060348956\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.002499958500266075\n",
      "Epoch: 615000, CNEP Losses: -1.4226896416533739, -0.6556762601230294, -0.2592883348560892\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.002499958500266075\n",
      "Epoch: 620000, CNEP Losses: -1.3348459978828207, -0.6401455381149426, -0.25527797273215835\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.002499958500266075\n",
      "Epoch: 625000, CNEP Losses: -1.4140315458174795, -0.6489100521067157, -0.25865598945976237\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.002499958500266075\n",
      "Epoch: 630000, CNEP Losses: -1.4650672821484507, -0.6409123315162957, -0.26524287733184176\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.002499958500266075\n",
      "Epoch: 635000, CNEP Losses: -1.4427081231091172, -0.6448289685986937, -0.25859276370946316\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.002499958500266075\n",
      "Epoch: 640000, CNEP Losses: -1.3820894355084747, -0.6537696228682995, -0.2594639190345071\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.002499958500266075\n",
      "Epoch: 645000, CNEP Losses: -1.4512277775453404, -0.637208922887221, -0.25850930602746086\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.002499958500266075\n",
      "Epoch: 650000, CNEP Losses: -1.465925697606802, -0.6567505002062768, -0.25064627529303546\n",
      "New best 8: 0.0024311363231390715\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.0024311363231390715\n",
      "Epoch: 655000, CNEP Losses: -1.421942099807039, -0.6517583442997187, -0.2558215231366456\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.0024311363231390715\n",
      "Epoch: 660000, CNEP Losses: -1.324910118023865, -0.6232904322318733, -0.2615425024190452\n",
      "New best 8: 0.002297587227076292\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.002297587227076292\n",
      "Epoch: 665000, CNEP Losses: -1.3947731472153218, -0.6433724317306653, -0.25591119831465187\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.002297587227076292\n",
      "Epoch: 670000, CNEP Losses: -1.4327438922666014, -0.588764840085106, -0.25822667312687264\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.002297587227076292\n",
      "Epoch: 675000, CNEP Losses: -1.438922308107093, -0.6493431583546102, -0.25838637428269723\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.002297587227076292\n",
      "Epoch: 680000, CNEP Losses: -1.3966525760894641, -0.6442870098612271, -0.2576260959844105\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.002297587227076292\n",
      "Epoch: 685000, CNEP Losses: -1.4586815599707887, -0.649132950165309, -0.26120366488872093\n",
      "Bests: 9.907743515213951e-05, 0.0005071411142125726, 0.002297587227076292\n",
      "Epoch: 690000, CNEP Losses: -1.4689807505946606, -0.6614779673468322, -0.25680093803727067\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "timestamp = int(time.time())\n",
    "root_folder = f'outputs/ablation/sines_2/2_4_8/{str(timestamp)}/'\n",
    "\n",
    "if not os.path.exists(root_folder):\n",
    "    os.makedirs(root_folder)\n",
    "\n",
    "if not os.path.exists(f'{root_folder}saved_models/'):\n",
    "    os.makedirs(f'{root_folder}saved_models/')\n",
    "\n",
    "if not os.path.exists(f'{root_folder}img/'):\n",
    "    os.makedirs(f'{root_folder}img/')\n",
    "\n",
    "torch.save(y, f'{root_folder}y.pt')\n",
    "\n",
    "\n",
    "epochs = 1_500_000\n",
    "epoch_iter = num_demos//batch_size  # number of batches per epoch (e.g. 100//32 = 3)\n",
    "v_epoch_iter = num_val//batch_size  # number of batches per validation (e.g. 100//32 = 3)\n",
    "avg_loss2, avg_loss4, avg_loss8 = 0, 0, 0\n",
    "\n",
    "val_per_epoch = 5000\n",
    "min_vl2, min_vl4, min_vl8 = 1000000, 1000000, 1000000\n",
    "\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "cnep_tl_path = f'{root_folder}cnep_training_loss.pt'\n",
    "cnep_ve_path = f'{root_folder}cnep_validation_error.pt'\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss2, epoch_loss4, epoch_loss8 = 0, 0, 0\n",
    "\n",
    "    traj_ids = torch.randperm(x.shape[0])[:batch_size*epoch_iter].chunk(epoch_iter)  # [:batch_size*epoch_iter] because nof_trajectories may be indivisible by batch_size\n",
    "\n",
    "    for i in range(epoch_iter):\n",
    "        prepare_masked_batch(y, traj_ids[i])\n",
    "\n",
    "        optimizer2.zero_grad()\n",
    "        pred2, gate2 = model2(obs, tar_x, obs_mask)\n",
    "        loss2, nll2 = model2.loss(pred2, gate2, tar_y, tar_mask)\n",
    "        loss2.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "\n",
    "        optimizer4.zero_grad()\n",
    "        pred4, gate4 = model4(obs, tar_x, obs_mask)\n",
    "        loss4, nll4 = model4.loss(pred4, gate4, tar_y, tar_mask)\n",
    "        loss4.backward()\n",
    "        optimizer4.step()\n",
    "\n",
    "\n",
    "        optimizer8.zero_grad()\n",
    "        pred8, gate8 = model8(obs, tar_x, obs_mask)\n",
    "        loss8, nll8 = model8.loss(pred8, gate8, tar_y, tar_mask)\n",
    "        loss8.backward()\n",
    "        optimizer8.step()\n",
    "\n",
    "        epoch_loss2 += nll2.item()\n",
    "        epoch_loss4 += nll4.item()\n",
    "        epoch_loss8 += nll8.item()\n",
    "\n",
    "    epoch_loss2 = epoch_loss2/epoch_iter\n",
    "    epoch_loss4 = epoch_loss4/epoch_iter\n",
    "    epoch_loss8 = epoch_loss8/epoch_iter\n",
    "\n",
    "    if epoch % val_per_epoch == 0:\n",
    "        with torch.no_grad():\n",
    "            v_traj_ids = torch.randperm(vx.shape[0])[:batch_size*v_epoch_iter].chunk(v_epoch_iter)\n",
    "            val_loss2, val_loss4, val_loss8 = 0, 0, 0\n",
    "\n",
    "            for j in range(v_epoch_iter):\n",
    "                prepare_masked_val_batch(vy, v_traj_ids[j])\n",
    "\n",
    "                p_wta, g_wta = model2.val(val_obs, val_tar_x, val_obs_mask)\n",
    "                dec_id = torch.argmax(g_wta.squeeze(1), dim=-1)\n",
    "                vp_means = p_wta[dec_id, torch.arange(batch_size), :, :dy]\n",
    "                val_loss2 += mse_loss(vp_means, val_tar_y).item()\n",
    "\n",
    "                p_wta, g_wta = model4.val(val_obs, val_tar_x, val_obs_mask)\n",
    "                dec_id = torch.argmax(g_wta.squeeze(1), dim=-1)\n",
    "                vp_means = p_wta[dec_id, torch.arange(batch_size), :, :dy]\n",
    "                val_loss4 += mse_loss(vp_means, val_tar_y).item()\n",
    "\n",
    "                p_wta, g_wta = model8.val(val_obs, val_tar_x, val_obs_mask)\n",
    "                dec_id = torch.argmax(g_wta.squeeze(1), dim=-1)\n",
    "                vp_means = p_wta[dec_id, torch.arange(batch_size), :, :dy]\n",
    "                val_loss8 += mse_loss(vp_means, val_tar_y).item()\n",
    "\n",
    "            if val_loss2 < min_vl2:\n",
    "                min_vl2 = val_loss2\n",
    "                print(f'New best 2: {min_vl2}')\n",
    "                torch.save(model2_.state_dict(), f'{root_folder}saved_models/wta2.pt')\n",
    "\n",
    "            if val_loss4 < min_vl4:\n",
    "                min_vl4 = val_loss4\n",
    "                print(f'New best 4: {min_vl4}')\n",
    "                torch.save(model4_.state_dict(), f'{root_folder}saved_models/wta4.pt')\n",
    "\n",
    "            if val_loss8 < min_vl8:\n",
    "                min_vl8 = val_loss8\n",
    "                print(f'New best 8: {min_vl8}')\n",
    "                torch.save(model8_.state_dict(), f'{root_folder}saved_models/wta8.pt')\n",
    "            \n",
    "            print(f'Bests: {min_vl2}, {min_vl4}, {min_vl8}')\n",
    "\n",
    "    avg_loss2 += epoch_loss2\n",
    "    avg_loss4 += epoch_loss4\n",
    "    avg_loss8 += epoch_loss8\n",
    "\n",
    "    if epoch % val_per_epoch == 0:\n",
    "        print(\"Epoch: {}, CNEP Losses: {}, {}, {}\".format(epoch, avg_loss2/val_per_epoch, avg_loss4/val_per_epoch, avg_loss8/val_per_epoch))\n",
    "        avg_loss2, avg_loss4, avg_loss8 = 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
