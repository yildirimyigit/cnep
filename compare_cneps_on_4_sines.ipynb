{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device : cuda:0\n"
     ]
    }
   ],
   "source": [
    "from models.cnp import CNP\n",
    "from models.wta_cnp import WTA_CNP\n",
    "\n",
    "from data.data_generators import *\n",
    "import torch\n",
    "\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "def get_free_gpu():\n",
    "    gpu_util = []\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        torch.cuda.set_device(i)  # Switch GPU\n",
    "        gpu_util.append((i, torch.cuda.utilization()))\n",
    "    gpu_util.sort(key=lambda x: x[1])\n",
    "    return gpu_util[0][0]\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    available_gpu = get_free_gpu()\n",
    "    if available_gpu == 0:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        device = torch.device(f\"cuda:{available_gpu}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device :\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "n_max_obs, n_max_tar = 10, 10\n",
    "\n",
    "t_steps = 200\n",
    "num_demos = 32\n",
    "num_classes = 4\n",
    "num_indiv = num_demos//num_classes  # number of demos per class\n",
    "noise_clip = 0.0\n",
    "dx, dy = 1, 1\n",
    "\n",
    "num_val = 8\n",
    "num_val_indiv = num_val//num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: torch.Size([32, 200, 1]) Y: torch.Size([32, 200, 1]) VX: torch.Size([8, 200, 1]) VY: torch.Size([8, 200, 1])\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "colors = [sns.color_palette('tab10')[0], sns.color_palette('tab10')[1], sns.color_palette('tab10')[2], sns.color_palette('tab10')[3]]\n",
    "sns.set_palette('tab10')\n",
    "\n",
    "x = torch.linspace(0, 1, 200).repeat(num_indiv, 1)\n",
    "y = torch.zeros(num_demos, t_steps, dy)\n",
    "\n",
    "vx = torch.linspace(0, 1, 200).repeat(num_val_indiv, 1)\n",
    "vy = torch.zeros(num_val, t_steps, dy)\n",
    "\n",
    "for i in range(num_classes):\n",
    "    start_ind = i*num_indiv\n",
    "    coeff = (i+1)/2*torch.pi\n",
    "    y[start_ind:start_ind+num_indiv] = (torch.unsqueeze(generate_sin(x*coeff), 2) +1)/2.0\n",
    "\n",
    "    noise = torch.unsqueeze(torch.clamp(torch.randn(vx.shape)*1e-4**0.5, min=0) - noise_clip, -1)\n",
    "\n",
    "    start_ind = i*num_val_indiv\n",
    "    vy[start_ind:start_ind+num_val_indiv] = y[start_ind:start_ind+num_val_indiv].clone() + noise\n",
    "\n",
    "x = torch.unsqueeze(x.repeat(num_classes, 1), 2)  # since dx = 1\n",
    "vx = torch.unsqueeze(vx.repeat(num_classes, 1), 2)\n",
    "print(\"X:\", x.shape, \"Y:\", y.shape, \"VX:\", vx.shape, \"VY:\", vy.shape)\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# for i in range(num_demos):\n",
    "#     plt.plot(x[i, :, 0].cpu(), y[i, :, 0].cpu(), label=f'Sine Wave {i+1}', linewidth=2.0, color=colors[i])\n",
    "#     # plt.plot(vx[i, :, 0].cpu(), vy[i, :, 0].cpu(), 'k', alpha=0.5)\n",
    "\n",
    "# plt.legend(loc='lower left', fontsize=14)\n",
    "# plt.grid(True)\n",
    "# plt.xlabel('Time (s)', fontsize=14)\n",
    "# plt.ylabel('Amplitude', fontsize=14)\n",
    "# plt.title(f'Sine Wave of 3 Different Frequencies', fontsize=16)\n",
    "# plt.savefig(f'/home/yigit/papers/yildirim_23_ral/fig/3.png', bbox_inches='tight')\n",
    "\n",
    "# x0, y0 = x.to(device_wta), y.to(device_wta)\n",
    "# x1, y1 = x.to(device_cnp), y.to(device_cnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x, y, traj_ids, device=device):\n",
    "    n_o = torch.randint(1, n_max_obs, (1,)).item()\n",
    "    n_t = torch.randint(1, n_max_tar, (1,)).item()\n",
    "    \n",
    "    tar = torch.zeros(batch_size, n_t, dx, device=device)\n",
    "    tar_val = torch.zeros(batch_size, n_t, dy, device=device)\n",
    "    obs = torch.zeros(batch_size, n_o, dx+dy, device=device)\n",
    "\n",
    "    for i in range(len(traj_ids)):\n",
    "        random_query_ids = torch.randperm(t_steps)\n",
    "        \n",
    "        o_ids = random_query_ids[:n_o]\n",
    "        t_ids = random_query_ids[n_o:n_o+n_t]\n",
    "\n",
    "        obs[i, :, :] = torch.cat((x[traj_ids[i], o_ids], y[traj_ids[i], o_ids]), dim=-1)\n",
    "        tar[i, :, :] = x[traj_ids[i], t_ids]\n",
    "        tar_val[i, :, :] = y[traj_ids[i], t_ids]\n",
    "\n",
    "    return obs, tar, tar_val\n",
    "\n",
    "def get_validation_batch(vx, vy, traj_ids, device=device):\n",
    "    num_obs = torch.randint(1, n_max_obs, (1,)).item()\n",
    "\n",
    "    obs = torch.zeros(batch_size, num_obs, dx+dy, device=device)\n",
    "    tar = torch.zeros(batch_size, t_steps, dx, device=device)\n",
    "    tar_val = torch.zeros(batch_size, t_steps, dy, device=device)\n",
    "\n",
    "    for i in range(len(traj_ids)):\n",
    "        random_query_ids = torch.randperm(t_steps)\n",
    "        o_ids = random_query_ids[:num_obs]\n",
    "\n",
    "        obs[i, :, :] = torch.cat((vx[traj_ids[i], o_ids], vy[traj_ids[i], o_ids]), dim=-1)\n",
    "        tar[i, :, :] = vx[traj_ids[i]]\n",
    "        tar_val[i, :, :] = vy[traj_ids[i]]\n",
    "\n",
    "    return obs, tar, tar_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnep2: 302338\n",
      "cnep4: 302468\n",
      "cnep8: 301720\n"
     ]
    }
   ],
   "source": [
    "model2 = WTA_CNP(1, 1, n_max_obs, n_max_tar, [128,128,128], num_decoders=2, decoder_hidden_dims=[306,306,306], batch_size=batch_size, scale_coefs=True).to(device)\n",
    "optimizer2 = torch.optim.Adam(lr=1e-4, params=model2.parameters())\n",
    "\n",
    "model4 = WTA_CNP(1, 1, n_max_obs, n_max_tar, [128,128,128], num_decoders=4, decoder_hidden_dims=[201,201,201], batch_size=batch_size, scale_coefs=True).to(device)\n",
    "optimizer4 = torch.optim.Adam(lr=1e-4, params=model4.parameters())\n",
    "\n",
    "model8 = WTA_CNP(1, 1, n_max_obs, n_max_tar, [128,128,128], num_decoders=8, decoder_hidden_dims=[128,128,128], batch_size=batch_size, scale_coefs=True).to(device)\n",
    "optimizer8 = torch.optim.Adam(lr=1e-4, params=model8.parameters())\n",
    "\n",
    "def get_parameter_count(model):\n",
    "    total_num = 0\n",
    "    for param in model.parameters():\n",
    "        total_num += param.shape.numel()\n",
    "    return total_num\n",
    "\n",
    "print(\"cnep2:\", get_parameter_count(model2))\n",
    "print(\"cnep4:\", get_parameter_count(model4))\n",
    "print(\"cnep8:\", get_parameter_count(model8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best 2: 0.8053796589374542\n",
      "New best 4: 0.8027530312538147\n",
      "New best 8: 0.8317125141620636\n",
      "Epoch: 0, WTA-Losses: 0.0012406293749809266, 0.001226790741086006, 0.0011888063549995423\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 57\u001b[0m\n\u001b[1;32m     55\u001b[0m pred8, gate8 \u001b[38;5;241m=\u001b[39m model8(obs, tar_x)\n\u001b[1;32m     56\u001b[0m loss8, nll8 \u001b[38;5;241m=\u001b[39m model8\u001b[38;5;241m.\u001b[39mloss(pred8, gate8, tar_y)\n\u001b[0;32m---> 57\u001b[0m \u001b[43mloss8\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m optimizer8\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     60\u001b[0m epoch_loss2 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m nll2\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "timestamp = int(time.time())\n",
    "root_folder = f'outputs/ablation/sines_4/2_4_8/{str(timestamp)}/'\n",
    "\n",
    "if not os.path.exists(root_folder):\n",
    "    os.makedirs(root_folder)\n",
    "\n",
    "if not os.path.exists(f'{root_folder}saved_models/'):\n",
    "    os.makedirs(f'{root_folder}saved_models/')\n",
    "\n",
    "if not os.path.exists(f'{root_folder}img/'):\n",
    "    os.makedirs(f'{root_folder}img/')\n",
    "\n",
    "torch.save(y, f'{root_folder}y.pt')\n",
    "\n",
    "\n",
    "epochs = 5_000_000\n",
    "epoch_iter = num_demos//batch_size  # number of batches per epoch (e.g. 100//32 = 3)\n",
    "v_epoch_iter = num_val//batch_size  # number of batches per validation (e.g. 100//32 = 3)\n",
    "avg_loss2, avg_loss4, avg_loss8 = 0, 0, 0\n",
    "\n",
    "val_per_epoch = 1000\n",
    "min_vl2, min_vl4, min_vl8 = 1000000, 1000000, 1000000\n",
    "\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "tl2, tl4, tl8 = [], [], []\n",
    "ve2, ve4, ve8 = [], [], []\n",
    "\n",
    "# wta_tr_loss_path = f'{root_folder}wta_training_loss.pt'\n",
    "# wta_val_err_path = f'{root_folder}wta_validation_error.pt'\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss2, epoch_loss4, epoch_loss8 = 0, 0, 0\n",
    "\n",
    "    traj_ids = torch.randperm(x.shape[0])[:batch_size*epoch_iter].chunk(epoch_iter)  # [:batch_size*epoch_iter] because nof_trajectories may be indivisible by batch_size\n",
    "\n",
    "    for i in range(epoch_iter):\n",
    "        optimizer2.zero_grad()\n",
    "\n",
    "        obs, tar_x, tar_y = get_batch(x, y, traj_ids[i], device)\n",
    "\n",
    "        pred2, gate2 = model2(obs, tar_x)\n",
    "        loss2, nll2 = model2.loss(pred2, gate2, tar_y)\n",
    "        loss2.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "        pred4, gate4 = model4(obs, tar_x)\n",
    "        loss4, nll4 = model4.loss(pred4, gate4, tar_y)\n",
    "        loss4.backward()\n",
    "        optimizer4.step()\n",
    "\n",
    "        pred8, gate8 = model8(obs, tar_x)\n",
    "        loss8, nll8 = model8.loss(pred8, gate8, tar_y)\n",
    "        loss8.backward()\n",
    "        optimizer8.step()\n",
    "\n",
    "        epoch_loss2 += nll2.item()\n",
    "        epoch_loss4 += nll4.item()\n",
    "        epoch_loss8 += nll8.item()\n",
    "\n",
    "    tl2.append(epoch_loss2)\n",
    "    tl4.append(epoch_loss4)\n",
    "    tl8.append(epoch_loss8)\n",
    "\n",
    "    if epoch % val_per_epoch == 0:\n",
    "        with torch.no_grad():\n",
    "            v_traj_ids = torch.randperm(vx.shape[0])[:batch_size*v_epoch_iter].chunk(v_epoch_iter)\n",
    "            val_loss2, val_loss4, val_loss8 = 0, 0, 0\n",
    "\n",
    "            for j in range(v_epoch_iter):\n",
    "                o_wta, t_wta, tr_wta = get_validation_batch(vx, vy, v_traj_ids[j], device=device)\n",
    "\n",
    "                p_wta, g_wta = model2(o_wta, t_wta)\n",
    "                dec_id = torch.argmax(g_wta.squeeze(1), dim=-1)\n",
    "                vp_means = p_wta[dec_id, torch.arange(batch_size), :, :dy]\n",
    "                val_loss2 += mse_loss(vp_means, tr_wta).item()\n",
    "\n",
    "                p_wta, g_wta = model4(o_wta, t_wta)\n",
    "                dec_id = torch.argmax(g_wta.squeeze(1), dim=-1)\n",
    "                vp_means = p_wta[dec_id, torch.arange(batch_size), :, :dy]\n",
    "                val_loss4 += mse_loss(vp_means, tr_wta).item()\n",
    "\n",
    "                p_wta, g_wta = model8(o_wta, t_wta)\n",
    "                dec_id = torch.argmax(g_wta.squeeze(1), dim=-1)\n",
    "                vp_means = p_wta[dec_id, torch.arange(batch_size), :, :dy]\n",
    "                val_loss8 += mse_loss(vp_means, tr_wta).item()\n",
    "\n",
    "            ve2.append(val_loss2)\n",
    "            ve4.append(val_loss4)\n",
    "            ve8.append(val_loss8)\n",
    "\n",
    "            if val_loss2 < min_vl2:\n",
    "                min_vl2 = val_loss2\n",
    "                print(f'New best 2: {min_vl2}')\n",
    "                torch.save(model2.state_dict(), f'{root_folder}saved_models/wta2.pt')\n",
    "\n",
    "            if val_loss4 < min_vl4:\n",
    "                min_vl4 = val_loss4\n",
    "                print(f'New best 4: {min_vl4}')\n",
    "                torch.save(model4.state_dict(), f'{root_folder}saved_models/wta4.pt')\n",
    "\n",
    "            if val_loss8 < min_vl8:\n",
    "                min_vl8 = val_loss8\n",
    "                print(f'New best 8: {min_vl8}')\n",
    "                torch.save(model8.state_dict(), f'{root_folder}saved_models/wta8.pt')\n",
    "  \n",
    "        # if epoch % (val_per_epoch*10) == 0:\n",
    "        #     draw_val_plot(root_folder, epoch)\n",
    "\n",
    "\n",
    "    avg_loss2 += epoch_loss2/epoch_iter\n",
    "    avg_loss4 += epoch_loss4/epoch_iter\n",
    "    avg_loss8 += epoch_loss8/epoch_iter\n",
    "\n",
    "    if epoch % val_per_epoch == 0:\n",
    "        print(\"Epoch: {}, WTA-Losses: {}, {}, {}\".format(epoch, avg_loss2/val_per_epoch, avg_loss4/val_per_epoch, avg_loss8/val_per_epoch))\n",
    "        avg_loss2, avg_loss4, avg_loss8 = 0, 0, 0\n",
    "\n",
    "# torch.save(torch.Tensor(training_loss_wta), wta_tr_loss_path)\n",
    "# torch.save(torch.Tensor(validation_error_wta), wta_val_err_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
