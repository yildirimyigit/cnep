{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device WTA: cpu Device CNP: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yigit/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from models.cnp import CNP\n",
    "from models.wta_cnp import WTA_CNP\n",
    "\n",
    "from data.data_generators import *\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device_wta = torch.device(\"cuda:0\")\n",
    "    device_cnp = torch.device(\"cuda:1\") if torch.cuda.device_count() > 1 else torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device_wta = torch.device(\"cpu\")\n",
    "    device_cnp = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device WTA:\", device_wta, \"Device CNP:\", device_cnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "n_max_obs, n_max_tar = 6, 6\n",
    "\n",
    "t_steps = 200\n",
    "num_demos = 2\n",
    "num_classes = 2\n",
    "num_indiv = num_demos//num_classes  # number of demos per class\n",
    "noise_clip = 0.0\n",
    "dx, dy = 1, 1\n",
    "\n",
    "num_val = 2\n",
    "num_val_indiv = num_val//num_classes\n",
    "\n",
    "colors = ['r', 'b']\n",
    "\n",
    "num_inc = 0\n",
    "num_exc = 0\n",
    "\n",
    "fixed_obs_ratio = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: torch.Size([2, 200, 1]) Y: torch.Size([2, 200, 1]) VX: torch.Size([2, 200, 1]) VY: torch.Size([2, 200, 1])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.linspace(0, 1, 200).repeat(num_indiv, 1)\n",
    "y = torch.zeros(num_demos, t_steps, dy)\n",
    "\n",
    "vx = torch.linspace(0, 1, 200).repeat(num_val_indiv, 1)\n",
    "vy = torch.zeros(num_val, t_steps, dy)\n",
    "\n",
    "noise = torch.clamp(torch.randn(x.shape)*1e-7**0.5, min=0) - noise_clip\n",
    "coeff = (torch.rand(num_indiv)*0.75+0.25).unsqueeze(-1)\n",
    "y[:num_indiv] = torch.unsqueeze(generate_sin(x)*coeff + noise, 2)\n",
    "y[num_indiv:] = -1 * y[:num_indiv]\n",
    "\n",
    "# coeff = (torch.rand(num_val_indiv)*0.75+0.25).unsqueeze(-1)\n",
    "noise = torch.clamp(torch.randn(vx.shape)*1e-4**0.5, min=0) - noise_clip\n",
    "vy[:num_val_indiv] = torch.unsqueeze(generate_sin(vx)*coeff + noise, 2)\n",
    "vy[num_val_indiv:] = -1 * vy[:num_val_indiv]\n",
    "\n",
    "x = torch.unsqueeze(x.repeat(num_classes, 1), 2)  # since dx = 1\n",
    "vx = torch.unsqueeze(vx.repeat(num_classes, 1), 2)\n",
    "print(\"X:\", x.shape, \"Y:\", y.shape, \"VX:\", vx.shape, \"VY:\", vy.shape)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for i in range(num_demos):\n",
    "    plt.plot(x[i, :, 0].cpu(), y[i, :, 0].cpu(), colors[i//num_indiv])\n",
    "    plt.plot(vx[i, :, 0].cpu(), vy[i, :, 0].cpu(), 'k')\n",
    "    \n",
    "\n",
    "x0, y0 = x.to(device_wta), y.to(device_wta)\n",
    "x1, y1 = x.to(device_cnp), y.to(device_cnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_batch(x, y, traj_ids, device=device_wta):\n",
    "#     global num_all\n",
    "#     n_t = torch.randint(1, n_max_tar, (1,)).item()  # 1 <= number of target points < n_max_tar \n",
    "#     n_o = torch.randint(1, n_max_obs, (1,)).item()\n",
    "\n",
    "#     obs = torch.zeros(batch_size, n_o, dx+dy, device=device)\n",
    "#     tar = torch.zeros(batch_size, n_t, dx, device=device)\n",
    "#     tar_val = torch.zeros(batch_size, n_t, dy, device=device)\n",
    "\n",
    "#     for i in range(len(traj_ids)):\n",
    "#         # num_all += 1\n",
    "#         # # random_query_ids = torch.randperm(t_steps)  # like this before but we need [0] and [-1] more often. That's why the trick below\n",
    "\n",
    "#         # # The trick\n",
    "#         # # region\n",
    "#         # nof_added_manually = 0\n",
    "#         # added_manually = []\n",
    "#         # if torch.rand(1) < 0.05:  # add first point 1% of the time\n",
    "#         #     nof_added_manually += 1\n",
    "#         #     added_manually.append(0)\n",
    "#         #     num_inc[0] += 1\n",
    "\n",
    "#         # if torch.rand(1) < 0.05:  # add last point 1% of the time\n",
    "#         #     nof_added_manually += 1\n",
    "#         #     added_manually.append(-1)\n",
    "#         #     num_inc[1] += 1\n",
    "\n",
    "#         # if n_o > nof_added_manually and nof_added_manually > 0:\n",
    "#         #     random_query_ids = torch.randperm(t_steps-2)+1  # excluding [0] and [-1]\n",
    "#         #     o_ids = torch.cat((torch.tensor(added_manually), random_query_ids[:n_o-nof_added_manually]))\n",
    "#         #     t_ids = random_query_ids[n_o-nof_added_manually:n_o-nof_added_manually+n_t]\n",
    "\n",
    "#         # else:\n",
    "#         #     random_query_ids = torch.randperm(t_steps)\n",
    "#         #     o_ids = random_query_ids[:n_o]\n",
    "#         #     t_ids = random_query_ids[n_o:n_o+n_t]\n",
    "\n",
    "#         # # endregion\n",
    "\n",
    "#         random_query_ids = torch.randperm(t_steps)\n",
    "#         o_ids = random_query_ids[:n_o]\n",
    "#         t_ids = random_query_ids[n_o:n_o+n_t]\n",
    "\n",
    "#         obs[i, :, :] = torch.cat((x[traj_ids[i], o_ids], y[traj_ids[i], o_ids]), dim=-1)\n",
    "#         tar[i, :, :] = x[traj_ids[i], t_ids]\n",
    "#         tar_val[i, :, :] = y[traj_ids[i], t_ids]\n",
    "\n",
    "#     # print(\"Obs:\", obs.shape, \"Tar:\", tar.shape, \"Tar_val:\", tar_val.shape)\n",
    "#     return obs, tar, tar_val\n",
    "\n",
    "\n",
    "def get_batch(x, y, traj_ids, device=device_wta):\n",
    "    global num_inc, num_exc\n",
    "\n",
    "\n",
    "    # if the following holds, we condition on 0, -1 or [0, -1] to estimate the rest\n",
    "    # if not, we condition on random-numbered random points\n",
    "    if torch.rand(1) < fixed_obs_ratio:\n",
    "        num_inc += 1\n",
    "        \n",
    "        if torch.rand(1) < 0.33:\n",
    "            n_o = 1  # [0]\n",
    "            n_t = t_steps - 1\n",
    "            o_ids = torch.tensor([0])\n",
    "            t_ids = torch.randperm(t_steps-1)+1  # excluding [0]\n",
    "        elif torch.rand(1) < 0.66:\n",
    "            n_o = 1  # [-1]\n",
    "            n_t = t_steps - 1\n",
    "            o_ids = torch.tensor([-1])\n",
    "            t_ids = torch.randperm(t_steps-1)  # excluding [-1]\n",
    "        else:\n",
    "            n_o = 2  # [0, -1]\n",
    "            n_t = t_steps - 2\n",
    "            o_ids = torch.tensor([0, -1])\n",
    "            t_ids = torch.randperm(t_steps-2)+1  # excluding [0] and [-1]\n",
    "\n",
    "        fixed = True\n",
    "    \n",
    "    else:\n",
    "        num_exc += 1\n",
    "        n_o = torch.randint(1, n_max_obs, (1,)).item()\n",
    "        n_t = torch.randint(1, n_max_tar, (1,)).item()\n",
    "        fixed = False\n",
    "\n",
    "    tar = torch.zeros(batch_size, n_t, dx, device=device)\n",
    "    tar_val = torch.zeros(batch_size, n_t, dy, device=device)\n",
    "    obs = torch.zeros(batch_size, n_o, dx+dy, device=device)\n",
    "    \n",
    "    for i in range(len(traj_ids)):\n",
    "        if not fixed:\n",
    "            random_query_ids = torch.randperm(t_steps) \n",
    "            \n",
    "            o_ids = random_query_ids[:n_o]\n",
    "            t_ids = random_query_ids[n_o:n_o+n_t]\n",
    "\n",
    "        obs[i, :, :] = torch.cat((x[traj_ids[i], o_ids], y[traj_ids[i], o_ids]), dim=-1)\n",
    "        tar[i, :, :] = x[traj_ids[i], t_ids]\n",
    "        tar_val[i, :, :] = y[traj_ids[i], t_ids]\n",
    "\n",
    "        # obs = torch.zeros(batch_size, n_o, dx+dy, device=device)\n",
    "        # for i in range(len(traj_ids)):\n",
    "        #     random_query_ids = torch.randperm(t_steps) \n",
    "            \n",
    "        #     o_ids = random_query_ids[:n_o]\n",
    "        #     t_ids = random_query_ids[n_o:n_o+n_t]\n",
    "\n",
    "        #     obs[i, :, :] = torch.cat((x[traj_ids[i], o_ids], y[traj_ids[i], o_ids]), dim=-1)\n",
    "        #     tar[i, :, :] = x[traj_ids[i], t_ids]\n",
    "        #     tar_val[i, :, :] = y[traj_ids[i], t_ids]\n",
    "\n",
    "    return obs, tar, tar_val\n",
    "\n",
    "def get_validation_batch(vx, vy, traj_ids, device=device_wta):\n",
    "    num_obs = torch.randint(1, n_max_obs, (1,)).item()\n",
    "\n",
    "    obs = torch.zeros(batch_size, num_obs, dx+dy, device=device)\n",
    "    tar = torch.zeros(batch_size, t_steps, dx, device=device)\n",
    "    tar_val = torch.zeros(batch_size, t_steps, dy, device=device)\n",
    "\n",
    "    for i in range(len(traj_ids)):\n",
    "        random_query_ids = torch.randperm(t_steps)\n",
    "        o_ids = random_query_ids[:num_obs]\n",
    "\n",
    "        obs[i, :, :] = torch.cat((vx[traj_ids[i], o_ids], vy[traj_ids[i], o_ids]), dim=-1)\n",
    "        tar[i, :, :] = vx[traj_ids[i]]\n",
    "        tar_val[i, :, :] = vy[traj_ids[i]]\n",
    "    # obs = torch.cat((vx[trajectory_ids, o_ids, :], vy[trajectory_ids, o_ids, :]), dim=-1).to(device)\n",
    "    # tar = vx[trajectory_ids, torch.arange(t_steps)].to(device)\n",
    "    # tar_val= vy[trajectory_ids, torch.arange(t_steps)].to(device)\n",
    "\n",
    "    return obs, tar, tar_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTA Model: WTA_CNP(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (decoders): ModuleList(\n",
      "    (0-1): 2 x Sequential(\n",
      "      (0): Linear(in_features=129, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (gate): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=2, bias=True)\n",
      "    (1): Softmax(dim=-1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_wta = WTA_CNP(1, 1, 6, 6, [128, 128, 128], num_decoders=2, decoder_hidden_dims=[128, 128, 128], batch_size=batch_size).to(device_wta)\n",
    "optimizer_wta = torch.optim.Adam(lr=1e-4, params=model_wta.parameters())\n",
    "\n",
    "model_cnp = CNP(input_dim=1, hidden_dim=128, output_dim=1, n_max_obs=6, n_max_tar=6, num_layers=3, batch_size=batch_size).to(device_cnp)\n",
    "optimizer_cnp = torch.optim.Adam(lr=1e-4, params=model_cnp.parameters())\n",
    "\n",
    "print(\"WTA Model:\", model_wta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTA-CNP: 100486\n",
      "CNP: 66818\n"
     ]
    }
   ],
   "source": [
    "def get_parameter_count(model):\n",
    "    total_num = 0\n",
    "    for param in model.parameters():\n",
    "        total_num += param.shape.numel()\n",
    "    return total_num\n",
    "\n",
    "print(\"WTA-CNP:\", get_parameter_count(model_wta))\n",
    "print(\"CNP:\", get_parameter_count(model_cnp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_val_plot(root_folder, epoch):\n",
    "\n",
    "    plt.ylim((-0.8, 0.8))\n",
    "\n",
    "    obs0 = torch.Tensor([0.0, 0.0]).unsqueeze(0).unsqueeze(0).to(device_wta)\n",
    "    obs1 = torch.Tensor([1.0, 0.0]).unsqueeze(0).unsqueeze(0).to(device_wta)\n",
    "    tar = torch.linspace(0, 1, 200).unsqueeze(0).unsqueeze(-1).to(device_wta)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_cnp0, _ = model_cnp(obs0, tar)\n",
    "        pred_wta0, gate0 = model_wta(obs0, tar)\n",
    "\n",
    "        pred_cnp1, _ = model_cnp(obs1, tar)\n",
    "        pred_wta1, gate1 = model_wta(obs1, tar)\n",
    "\n",
    "    plt.scatter(0.0, 0.0, c='k')\n",
    "    plt.plot(torch.linspace(0, 1, 200), pred_wta0[0,0,:,0].cpu(), 'r', alpha=gate0[0, 0, 0].item())  # wta pred 0\n",
    "    plt.plot(torch.linspace(0, 1, 200), pred_wta0[1,0,:,0].cpu(), 'r', alpha=gate0[0, 0, 1].item())  # wta pred 1\n",
    "    plt.plot(torch.linspace(0, 1, 200), pred_cnp0[:, :, :model_cnp.output_dim].squeeze(0).cpu(), 'b')  # cnp pred\n",
    "    plt.plot(torch.linspace(0, 1, 200), vy[0].squeeze(-1).cpu(), 'k', alpha=0.3)  # data\n",
    "    plt.plot(torch.linspace(0, 1, 200), vy[1].squeeze(-1).cpu(), 'k', alpha=0.3)  # data\n",
    "\n",
    "    plt.savefig(f'{root_folder}img/0_{epoch}.png')\n",
    "    plt.close()\n",
    "\n",
    "    ##################\n",
    "\n",
    "    plt.ylim((-0.8, 0.8))\n",
    "\n",
    "    plt.scatter(1.0, 0.0, c='k')\n",
    "    plt.plot(torch.linspace(0, 1, 200), pred_wta1[0,0,:,0].cpu(), 'r', alpha=gate1[0, 0, 0].item())  # wta pred 0\n",
    "    plt.plot(torch.linspace(0, 1, 200), pred_wta1[1,0,:,0].cpu(), 'r', alpha=gate1[0, 0, 1].item())  # wta pred 1\n",
    "    plt.plot(torch.linspace(0, 1, 200), pred_cnp1[:, :, :model_cnp.output_dim].squeeze(0).cpu(), 'b')  # cnp pred\n",
    "    plt.plot(torch.linspace(0, 1, 200), vy[0].squeeze(-1).cpu(), 'k', alpha=0.3)  # data\n",
    "    plt.plot(torch.linspace(0, 1, 200), vy[1].squeeze(-1).cpu(), 'k', alpha=0.3)  # data\n",
    "\n",
    "    plt.savefig(f'{root_folder}img/1_{epoch}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4623]])\n",
      "tensor([[-0.7343]])\n",
      "tensor([[0.7337],\n",
      "        [0.8693],\n",
      "        [0.5477],\n",
      "        [0.1508],\n",
      "        [0.0452]])\n",
      "tensor([[-0.5487],\n",
      "        [-0.2975],\n",
      "        [-0.7309],\n",
      "        [-0.3405],\n",
      "        [-0.1048]])\n",
      "tensor([[0.5025],\n",
      "        [0.6030],\n",
      "        [0.8894]])\n",
      "tensor([[0.7391],\n",
      "        [0.7078],\n",
      "        [0.2593]])\n",
      "tensor([[0.9045],\n",
      "        [0.6482],\n",
      "        [0.1407]])\n",
      "tensor([[0.2269],\n",
      "        [0.6618],\n",
      "        [0.3216]])\n",
      "(WTA)New best: 0.548965573310852\n",
      "(CNP)New best: 0.5636155605316162\n",
      "Epoch: 0, WTA-Loss: 0.014969445466995239, CNP-Loss: 0.014151785373687744\n",
      "tensor([[0.1307]])\n",
      "tensor([[-0.2952]])\n",
      "tensor([[0.5980],\n",
      "        [0.6080],\n",
      "        [0.4824],\n",
      "        [0.6482],\n",
      "        [0.7337]])\n",
      "tensor([[-0.7043],\n",
      "        [-0.6971],\n",
      "        [-0.7381],\n",
      "        [-0.6618],\n",
      "        [-0.5487]])\n",
      "tensor([[0.5025],\n",
      "        [0.9397]])\n",
      "tensor([[0.7391],\n",
      "        [0.1393]])\n",
      "tensor([[0.4271],\n",
      "        [0.2060]])\n",
      "tensor([[0.7200],\n",
      "        [0.4524]])\n",
      "tensor([[0.0402],\n",
      "        [0.5578],\n",
      "        [0.5377],\n",
      "        [0.4523],\n",
      "        [0.1457]])\n",
      "tensor([[0.0994],\n",
      "        [0.7271],\n",
      "        [0.7339],\n",
      "        [0.7373],\n",
      "        [0.3268]])\n",
      "tensor([[0.7437]])\n",
      "tensor([[0.5364]])\n",
      "tensor([[0.3668],\n",
      "        [0.6935],\n",
      "        [0.3819],\n",
      "        [0.3769]])\n",
      "tensor([[-0.6845],\n",
      "        [-0.6073],\n",
      "        [-0.6888],\n",
      "        [-0.6845]])\n",
      "tensor([[0.9899],\n",
      "        [0.5025],\n",
      "        [0.6432]])\n",
      "tensor([[-0.0247],\n",
      "        [-0.7391],\n",
      "        [-0.6657]])\n",
      "tensor([[0.5025],\n",
      "        [0.5628],\n",
      "        [0.8593]])\n",
      "tensor([[-0.7391],\n",
      "        [-0.7247],\n",
      "        [-0.3170]])\n",
      "tensor([[0.4673]])\n",
      "tensor([[-0.7352]])\n",
      "tensor([[0.6935],\n",
      "        [0.6231]])\n",
      "tensor([[0.6073],\n",
      "        [0.6959]])\n",
      "tensor([[0.6281],\n",
      "        [0.1106]])\n",
      "tensor([[0.6800],\n",
      "        [0.2562]])\n",
      "Obs: tensor([ 0, -1])\n",
      "tensor([[0.],\n",
      "        [1.]])\n",
      "tensor([[-0.0000e+00],\n",
      "        [6.4613e-08]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [1, 2].  Tensor sizes: [2, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/yigit/projects/mbcnp/compare_cnp_wta_diff_for_cnp.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yigit/projects/mbcnp/compare_cnp_wta_diff_for_cnp.ipynb#X10sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m optimizer_wta\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yigit/projects/mbcnp/compare_cnp_wta_diff_for_cnp.ipynb#X10sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m optimizer_cnp\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/yigit/projects/mbcnp/compare_cnp_wta_diff_for_cnp.ipynb#X10sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m obs_wta, tar_x_wta, tar_y_wta \u001b[39m=\u001b[39m get_batch(x, y, traj_ids[i], device_wta)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yigit/projects/mbcnp/compare_cnp_wta_diff_for_cnp.ipynb#X10sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m obs_cnp, tar_x_cnp, tar_y_cnp \u001b[39m=\u001b[39m get_batch(x, y, traj_ids[i], device_cnp)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yigit/projects/mbcnp/compare_cnp_wta_diff_for_cnp.ipynb#X10sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m pred_wta, gate_wta \u001b[39m=\u001b[39m model_wta(obs_wta, tar_x_wta)\n",
      "\u001b[1;32m/home/yigit/projects/mbcnp/compare_cnp_wta_diff_for_cnp.ipynb Cell 8\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(x, y, traj_ids, device)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yigit/projects/mbcnp/compare_cnp_wta_diff_for_cnp.ipynb#X10sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m \u001b[39mprint\u001b[39m(x[traj_ids[i], o_ids])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yigit/projects/mbcnp/compare_cnp_wta_diff_for_cnp.ipynb#X10sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39mprint\u001b[39m(y[traj_ids[i], o_ids])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/yigit/projects/mbcnp/compare_cnp_wta_diff_for_cnp.ipynb#X10sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m obs[i, :, :] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((x[traj_ids[i], o_ids], y[traj_ids[i], o_ids]), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yigit/projects/mbcnp/compare_cnp_wta_diff_for_cnp.ipynb#X10sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m tar[i, :, :] \u001b[39m=\u001b[39m x[traj_ids[i], t_ids]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yigit/projects/mbcnp/compare_cnp_wta_diff_for_cnp.ipynb#X10sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m tar_val[i, :, :] \u001b[39m=\u001b[39m y[traj_ids[i], t_ids]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [1, 2].  Tensor sizes: [2, 2]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "timestamp = int(time.time())\n",
    "root_folder = f'outputs/diff/{str(timestamp)}/'\n",
    "\n",
    "if not os.path.exists(root_folder):\n",
    "    os.makedirs(root_folder)\n",
    "\n",
    "if not os.path.exists(f'{root_folder}saved_models/'):\n",
    "    os.makedirs(f'{root_folder}saved_models/')\n",
    "\n",
    "if not os.path.exists(f'{root_folder}img/'):\n",
    "    os.makedirs(f'{root_folder}img/')\n",
    "\n",
    "\n",
    "epochs = 300_000\n",
    "epoch_iter = num_demos//batch_size  # number of batches per epoch (e.g. 100//32 = 3)\n",
    "v_epoch_iter = num_val//batch_size  # number of batches per validation (e.g. 100//32 = 3)\n",
    "avg_loss_wta, avg_loss_cnp = 0, 0\n",
    "\n",
    "val_per_epoch = 1000\n",
    "min_val_loss_wta, min_val_loss_cnp = 1000000, 1000000\n",
    "\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "training_loss_wta, validation_error_wta = [], []\n",
    "training_loss_cnp, validation_error_cnp = [], []\n",
    "\n",
    "wta_tr_loss_path = f'{root_folder}wta_training_loss.pt'\n",
    "wta_val_err_path = f'{root_folder}wta_validation_error.pt'\n",
    "cnp_tr_loss_path = f'{root_folder}cnp_training_loss.pt'\n",
    "cnp_val_err_path = f'{root_folder}cnp_validation_error.pt'\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss_wta, epoch_loss_cnp = 0, 0\n",
    "\n",
    "    traj_ids = torch.randperm(x.shape[0])[:batch_size*epoch_iter].chunk(epoch_iter)  # [:batch_size*epoch_iter] because nof_trajectories may be indivisible by batch_size\n",
    "\n",
    "    for i in range(epoch_iter):\n",
    "        optimizer_wta.zero_grad()\n",
    "        optimizer_cnp.zero_grad()\n",
    "\n",
    "        obs_wta, tar_x_wta, tar_y_wta = get_batch(x, y, traj_ids[i], device_wta)\n",
    "        obs_cnp, tar_x_cnp, tar_y_cnp = obs_wta.clone(), tar_x_wta.clone(), tar_y_wta.clone()\n",
    "\n",
    "        pred_wta, gate_wta = model_wta(obs_wta, tar_x_wta)\n",
    "        pred_cnp, encoded_rep_cnp = model_cnp(obs_cnp, tar_x_cnp)\n",
    "\n",
    "        loss_wta, wta_nll = model_wta.loss(pred_wta, gate_wta, tar_y_wta)\n",
    "\n",
    "        loss_wta.backward()\n",
    "        optimizer_wta.step()\n",
    "\n",
    "        loss_cnp = model_cnp.loss(pred_cnp, tar_y_cnp)\n",
    "        loss_cnp.backward()\n",
    "        optimizer_cnp.step()\n",
    "\n",
    "        epoch_loss_wta += wta_nll.item()\n",
    "        epoch_loss_cnp += loss_cnp.item()\n",
    "\n",
    "    training_loss_wta.append(epoch_loss_wta)\n",
    "    training_loss_cnp.append(epoch_loss_cnp)\n",
    "\n",
    "    if epoch % val_per_epoch == 0:\n",
    "        with torch.no_grad():\n",
    "            v_traj_ids = torch.randperm(vx.shape[0])[:batch_size*v_epoch_iter].chunk(v_epoch_iter)\n",
    "            val_loss_wta, val_loss_cnp = 0, 0\n",
    "\n",
    "            for j in range(v_epoch_iter):\n",
    "                o_wta, t_wta, tr_wta = get_validation_batch(vx, vy, v_traj_ids[j], device=device_wta)\n",
    "                o_cnp, t_cnp, tr_cnp = o_wta.clone(), t_wta.clone(), tr_wta.clone()\n",
    "\n",
    "                p_wta, g_wta = model_wta(o_wta, t_wta)\n",
    "                dec_id = torch.argmax(g_wta.squeeze(1), dim=-1)\n",
    "                vp_means = p_wta[dec_id, torch.arange(batch_size), :, :dy]\n",
    "                val_loss_wta += mse_loss(vp_means, tr_wta).item()\n",
    "\n",
    "                pred_cnp, encoded_rep = model_cnp(o_cnp, t_cnp)\n",
    "                val_loss_cnp += mse_loss(pred_cnp[:, :, :model_cnp.output_dim], tr_cnp)\n",
    "\n",
    "\n",
    "            validation_error_wta.append(val_loss_wta)\n",
    "            if val_loss_wta < min_val_loss_wta:\n",
    "                min_val_loss_wta = val_loss_wta\n",
    "                print(f'(WTA)New best: {min_val_loss_wta}')\n",
    "                torch.save(model_wta.state_dict(), f'{root_folder}saved_models/wta_on_synth.pt')\n",
    "\n",
    "            validation_error_cnp.append(val_loss_cnp.item())\n",
    "            if val_loss_cnp < min_val_loss_cnp:\n",
    "                min_val_loss_cnp = val_loss_cnp\n",
    "                print(f'(CNP)New best: {min_val_loss_cnp}')\n",
    "                torch.save(model_cnp.state_dict(), f'{root_folder}saved_models/cnp_on_synth.pt')\n",
    "\n",
    "        \n",
    "            \n",
    "        draw_val_plot(root_folder, epoch)\n",
    "\n",
    "\n",
    "    avg_loss_wta += epoch_loss_wta\n",
    "    avg_loss_cnp += epoch_loss_cnp\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: {}, WTA-Loss: {}, CNP-Loss: {}\".format(epoch, avg_loss_wta/100, avg_loss_cnp/100))\n",
    "        avg_loss_wta, avg_loss_cnp = 0, 0\n",
    "\n",
    "    if epoch % 100000:\n",
    "        torch.save(torch.Tensor(training_loss_wta), wta_tr_loss_path)\n",
    "        torch.save(torch.Tensor(validation_error_wta), wta_val_err_path)\n",
    "        torch.save(torch.Tensor(training_loss_cnp), cnp_tr_loss_path)\n",
    "        torch.save(torch.Tensor(validation_error_cnp), cnp_val_err_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (920071870.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [22]\u001b[0;36m\u001b[0m\n\u001b[0;31m    obs.\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# get_batch(x, y, torch.tensor([0]))\n",
    "#o_wta, t_wta, tr_wta = get_validation_batch(vx, vy, v_traj_ids[j])\n",
    "#print(o_wta[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import glob\n",
    "\n",
    "# def make_gif(frame_folder):\n",
    "#     frames = [Image.open(image) for image in glob.glob(f\"{frame_folder}/*.png\")]\n",
    "#     frame_one = frames[0]\n",
    "#     frame_one.save(f'{root_folder}img/animated.gif', format=\"GIF\", append_images=frames,\n",
    "#                save_all=True, duration=1000, loop=0)\n",
    "    \n",
    "# make_gif(f'{root_folder}img/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(y, f'{root_folder}y.pt')\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_exc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/yigit/projects/mbcnp/compare_cnp_wta_diff_for_cnp.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/yigit/projects/mbcnp/compare_cnp_wta_diff_for_cnp.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnum_inc / num_all: \u001b[39m\u001b[39m{\u001b[39;00mnum_inc\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnum_inc\u001b[39m+\u001b[39mnum_exc\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_exc' is not defined"
     ]
    }
   ],
   "source": [
    "print(f'num_inc / num_all: {num_inc}/{num_inc+num_exc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
