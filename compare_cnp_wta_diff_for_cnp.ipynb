{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cnp import CNP\n",
    "from models.wta_cnp import WTA_CNP\n",
    "\n",
    "from data.data_generators import *\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device_wta = torch.device(\"cuda:0\")\n",
    "    device_cnp = torch.device(\"cuda:1\") if torch.cuda.device_count() > 1 else torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device_wta = torch.device(\"cpu\")\n",
    "    device_cnp = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "n_max_obs, n_max_tar = 6, 6\n",
    "\n",
    "t_steps = 200\n",
    "num_demos = 2\n",
    "num_classes = 2\n",
    "num_indiv = num_demos//num_classes  # number of demos per class\n",
    "noise_clip = 0.0\n",
    "dx, dy = 1, 1\n",
    "\n",
    "num_val = 2\n",
    "num_val_indiv = num_val//num_classes\n",
    "\n",
    "colors = ['r', 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: torch.Size([2, 200, 1]) Y: torch.Size([2, 200, 1]) VX: torch.Size([2, 200, 1]) VY: torch.Size([2, 200, 1])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.linspace(0, 1, 200).repeat(num_indiv, 1)\n",
    "y = torch.zeros(num_demos, t_steps, dy)\n",
    "\n",
    "vx = torch.linspace(0, 1, 200).repeat(num_val_indiv, 1)\n",
    "vy = torch.zeros(num_val, t_steps, dy)\n",
    "\n",
    "noise = torch.clamp(torch.randn(x.shape)*1e-7**0.5, min=0) - noise_clip\n",
    "coeff = (torch.rand(num_indiv)*0.75+0.25).unsqueeze(-1)\n",
    "y[:num_indiv] = torch.unsqueeze(generate_sin(x)*coeff + noise, 2)\n",
    "y[num_indiv:] = -1 * y[:num_indiv]\n",
    "\n",
    "# coeff = (torch.rand(num_val_indiv)*0.75+0.25).unsqueeze(-1)\n",
    "noise = torch.clamp(torch.randn(vx.shape)*1e-4**0.5, min=0) - noise_clip\n",
    "vy[:num_val_indiv] = torch.unsqueeze(generate_sin(vx)*coeff + noise, 2)\n",
    "vy[num_val_indiv:] = -1 * vy[:num_val_indiv]\n",
    "\n",
    "x = torch.unsqueeze(x.repeat(num_classes, 1), 2)  # since dx = 1\n",
    "vx = torch.unsqueeze(vx.repeat(num_classes, 1), 2)\n",
    "print(\"X:\", x.shape, \"Y:\", y.shape, \"VX:\", vx.shape, \"VY:\", vy.shape)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for i in range(num_demos):\n",
    "    plt.plot(x[i, :, 0].cpu(), y[i, :, 0].cpu(), colors[i//num_indiv])\n",
    "    plt.plot(vx[i, :, 0].cpu(), vy[i, :, 0].cpu(), 'k')\n",
    "    \n",
    "\n",
    "x0, y0 = x.to(device_wta), y.to(device_wta)\n",
    "x1, y1 = x.to(device_cnp), y.to(device_cnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x, y, traj_ids, device=device_wta):\n",
    "    n_t = torch.randint(1, n_max_tar, (1,)).item()  # 1 <= number of target points < n_max_tar \n",
    "    n_o = torch.randint(1, n_max_obs, (1,)).item()\n",
    "\n",
    "    obs = torch.zeros(batch_size, n_o, dx+dy, device=device)\n",
    "    tar = torch.zeros(batch_size, n_t, dx, device=device)\n",
    "    tar_val = torch.zeros(batch_size, n_t, dy, device=device)\n",
    "\n",
    "    for i in range(len(traj_ids)):\n",
    "        # random_query_ids = torch.randperm(t_steps)  # like this before but we need [0] and [-1] more often. That's why the trick below\n",
    "\n",
    "        # The trick\n",
    "        # region\n",
    "        nof_added_manually = 0\n",
    "        added_manually = []\n",
    "        if torch.rand(1) < 0.01:  # add first point 1% of the time\n",
    "            nof_added_manually += 1\n",
    "            added_manually.append(0)\n",
    "\n",
    "        if torch.rand(1) < 0.01:  # add last point 1% of the time\n",
    "            nof_added_manually += 1\n",
    "            added_manually.append(-1)\n",
    "\n",
    "        if n_o > nof_added_manually and nof_added_manually > 0:\n",
    "            random_query_ids = torch.randperm(t_steps-2)+1  # excluding [0] and [-1]\n",
    "            o_ids = torch.cat((torch.tensor(added_manually), random_query_ids[:n_o-nof_added_manually]))\n",
    "            t_ids = random_query_ids[n_o-nof_added_manually:n_o-nof_added_manually+n_t]\n",
    "\n",
    "        else:\n",
    "            random_query_ids = torch.randperm(t_steps)\n",
    "            o_ids = random_query_ids[:n_o]\n",
    "            t_ids = random_query_ids[n_o:n_o+n_t]\n",
    "\n",
    "        # endregion\n",
    "\n",
    "        obs[i, :, :] = torch.cat((x[traj_ids[i], o_ids], y[traj_ids[i], o_ids]), dim=-1)\n",
    "        tar[i, :, :] = x[traj_ids[i], t_ids]\n",
    "        tar_val[i, :, :] = y[traj_ids[i], t_ids]\n",
    "\n",
    "    # print(\"Obs:\", obs.shape, \"Tar:\", tar.shape, \"Tar_val:\", tar_val.shape)\n",
    "    return obs, tar, tar_val\n",
    "\n",
    "\n",
    "def get_validation_batch(vx, vy, traj_ids, device=device_wta):\n",
    "    num_obs = torch.randint(1, n_max_obs, (1,)).item()\n",
    "\n",
    "    obs = torch.zeros(batch_size, num_obs, dx+dy, device=device)\n",
    "    tar = torch.zeros(batch_size, t_steps, dx, device=device)\n",
    "    tar_val = torch.zeros(batch_size, t_steps, dy, device=device)\n",
    "\n",
    "    for i in range(len(traj_ids)):\n",
    "        random_query_ids = torch.randperm(t_steps)\n",
    "        o_ids = random_query_ids[:num_obs]\n",
    "\n",
    "        obs[i, :, :] = torch.cat((vx[traj_ids[i], o_ids], vy[traj_ids[i], o_ids]), dim=-1)\n",
    "        tar[i, :, :] = vx[traj_ids[i]]\n",
    "        tar_val[i, :, :] = vy[traj_ids[i]]\n",
    "    # obs = torch.cat((vx[trajectory_ids, o_ids, :], vy[trajectory_ids, o_ids, :]), dim=-1).to(device)\n",
    "    # tar = vx[trajectory_ids, torch.arange(t_steps)].to(device)\n",
    "    # tar_val= vy[trajectory_ids, torch.arange(t_steps)].to(device)\n",
    "\n",
    "    return obs, tar, tar_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTA Model: WTA_CNP(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (decoders): ModuleList(\n",
      "    (0-1): 2 x Sequential(\n",
      "      (0): Linear(in_features=129, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (gate): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=2, bias=True)\n",
      "    (1): Softmax(dim=-1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_wta = WTA_CNP(1, 1, 6, 6, [256, 256, 256], num_decoders=2, decoder_hidden_dims=[256, 256], batch_size=batch_size).to(device_wta)\n",
    "optimizer_wta = torch.optim.Adam(lr=1e-4, params=model_wta.parameters())\n",
    "\n",
    "model_cnp = CNP(input_dim=1, hidden_dim=256, output_dim=1, n_max_obs=6, n_max_tar=6, num_layers=3, batch_size=batch_size).to(device_cnp)\n",
    "optimizer_cnp = torch.optim.Adam(lr=1e-4, params=model_cnp.parameters())\n",
    "\n",
    "print(\"WTA Model:\", model_wta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTA-CNP: 67462\n",
      "CNP: 66818\n"
     ]
    }
   ],
   "source": [
    "def get_parameter_count(model):\n",
    "    total_num = 0\n",
    "    for param in model.parameters():\n",
    "        total_num += param.shape.numel()\n",
    "    return total_num\n",
    "\n",
    "print(\"WTA-CNP:\", get_parameter_count(model_wta))\n",
    "print(\"CNP:\", get_parameter_count(model_cnp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(WTA)New best: 0.7755774557590485\n",
      "(CNP)New best: 0.7850006818771362\n",
      "Epoch: 0, WTA-Loss: 0.014836719036102295, CNP-Loss: 0.021895938515663148\n",
      "Epoch: 100, WTA-Loss: 1.1085663827881218, CNP-Loss: 0.940930322110653\n",
      "Epoch: 200, WTA-Loss: 0.3794204934616573, CNP-Loss: 0.4791977316094562\n",
      "Epoch: 300, WTA-Loss: 0.3856673853704706, CNP-Loss: 0.3117330567492172\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/yigit/projects/mbcnp/compare_cnp_wta_diff_for_cnp.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yigit/projects/mbcnp/compare_cnp_wta_diff_for_cnp.ipynb#W6sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m pred_wta, gate_wta \u001b[39m=\u001b[39m model_wta(obs_wta, tar_x_wta)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yigit/projects/mbcnp/compare_cnp_wta_diff_for_cnp.ipynb#W6sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m pred_cnp, encoded_rep_cnp \u001b[39m=\u001b[39m model_cnp(obs_cnp, tar_x_cnp)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/yigit/projects/mbcnp/compare_cnp_wta_diff_for_cnp.ipynb#W6sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m loss_wta, wta_nll \u001b[39m=\u001b[39m model_wta\u001b[39m.\u001b[39;49mloss(pred_wta, gate_wta, tar_y_wta)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yigit/projects/mbcnp/compare_cnp_wta_diff_for_cnp.ipynb#W6sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m loss_wta\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yigit/projects/mbcnp/compare_cnp_wta_diff_for_cnp.ipynb#W6sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m optimizer_wta\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/projects/mbcnp/models/wta_cnp.py:81\u001b[0m, in \u001b[0;36mWTA_CNP.loss\u001b[0;34m(self, pred, gate_vals, real)\u001b[0m\n\u001b[1;32m     78\u001b[0m pred_stds \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftplus(pred[:, :, :, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_dim:])\n\u001b[1;32m     80\u001b[0m pred_dists \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdistributions\u001b[39m.\u001b[39mNormal(pred_means, pred_stds)  \u001b[39m# <num_decoders>-many gaussians\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m dec_loss \u001b[39m=\u001b[39m (\u001b[39m-\u001b[39mpred_dists\u001b[39m.\u001b[39;49mlog_prob(real))\u001b[39m.\u001b[39mmean((\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))  \u001b[39m# (num_decoders, batch_size) - mean over tar and output_dim\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m#############\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39m# Actual loss\u001b[39;00m\n\u001b[1;32m     85\u001b[0m nll \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmatmul(gate_vals, dec_loss)\u001b[39m.\u001b[39mmean()  \u001b[39m# (batch_size, batch_size).mean() = scalar\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/distributions/normal.py:83\u001b[0m, in \u001b[0;36mNormal.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     81\u001b[0m var \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[1;32m     82\u001b[0m log_scale \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39mlog(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale, Real) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale\u001b[39m.\u001b[39mlog()\n\u001b[0;32m---> 83\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m((value \u001b[39m-\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloc) \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m \u001b[39m2\u001b[39;49m) \u001b[39m/\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m var) \u001b[39m-\u001b[39m log_scale \u001b[39m-\u001b[39m math\u001b[39m.\u001b[39mlog(math\u001b[39m.\u001b[39msqrt(\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m math\u001b[39m.\u001b[39mpi))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py:40\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[39mif\u001b[39;00m has_torch_function(args):\n\u001b[1;32m     39\u001b[0m         \u001b[39mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     41\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "timestamp = int(time.time())\n",
    "root_folder = f'outputs/diff/{str(timestamp)}/'\n",
    "\n",
    "if not os.path.exists(root_folder):\n",
    "    os.makedirs(root_folder)\n",
    "\n",
    "if not os.path.exists(f'{root_folder}saved_models/'):\n",
    "    os.makedirs(f'{root_folder}saved_models/')\n",
    "\n",
    "\n",
    "epochs = 250_000\n",
    "epoch_iter = num_demos//batch_size  # number of batches per epoch (e.g. 100//32 = 3)\n",
    "v_epoch_iter = num_val//batch_size  # number of batches per validation (e.g. 100//32 = 3)\n",
    "avg_loss_wta, avg_loss_cnp = 0, 0\n",
    "\n",
    "val_per_epoch = 1000\n",
    "min_val_loss_wta, min_val_loss_cnp = 1000000, 1000000\n",
    "\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "training_loss_wta, validation_error_wta = [], []\n",
    "training_loss_cnp, validation_error_cnp = [], []\n",
    "\n",
    "wta_tr_loss_path = f'{root_folder}wta_training_loss.pt'\n",
    "wta_val_err_path = f'{root_folder}wta_validation_error.pt'\n",
    "cnp_tr_loss_path = f'{root_folder}cnp_training_loss.pt'\n",
    "cnp_val_err_path = f'{root_folder}cnp_validation_error.pt'\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss_wta, epoch_loss_cnp = 0, 0\n",
    "\n",
    "    traj_ids = torch.randperm(x.shape[0])[:batch_size*epoch_iter].chunk(epoch_iter)  # [:batch_size*epoch_iter] because nof_trajectories may be indivisible by batch_size\n",
    "\n",
    "    for i in range(epoch_iter):\n",
    "        optimizer_wta.zero_grad()\n",
    "        optimizer_cnp.zero_grad()\n",
    "\n",
    "        obs_wta, tar_x_wta, tar_y_wta = get_batch(x, y, traj_ids[i], device_wta)\n",
    "        obs_cnp, tar_x_cnp, tar_y_cnp = get_batch(x, y, traj_ids[i], device_cnp)\n",
    "\n",
    "        pred_wta, gate_wta = model_wta(obs_wta, tar_x_wta)\n",
    "        pred_cnp, encoded_rep_cnp = model_cnp(obs_cnp, tar_x_cnp)\n",
    "\n",
    "        loss_wta, wta_nll = model_wta.loss(pred_wta, gate_wta, tar_y_wta)\n",
    "\n",
    "        loss_wta.backward()\n",
    "        optimizer_wta.step()\n",
    "\n",
    "        loss_cnp = model_cnp.loss(pred_cnp, tar_y_cnp)\n",
    "        loss_cnp.backward()\n",
    "        optimizer_cnp.step()\n",
    "\n",
    "        epoch_loss_wta += wta_nll.item()\n",
    "        epoch_loss_cnp += loss_cnp.item()\n",
    "\n",
    "    training_loss_wta.append(epoch_loss_wta)\n",
    "    training_loss_cnp.append(epoch_loss_cnp)\n",
    "\n",
    "    if epoch % val_per_epoch == 0:\n",
    "        with torch.no_grad():\n",
    "            v_traj_ids = torch.randperm(vx.shape[0])[:batch_size*v_epoch_iter].chunk(v_epoch_iter)\n",
    "            val_loss_wta, val_loss_cnp = 0, 0\n",
    "            \n",
    "            for j in range(v_epoch_iter):\n",
    "                o_wta, t_wta, tr_wta = get_validation_batch(vx, vy, v_traj_ids[j], device=device_wta)\n",
    "                o_cnp, t_cnp, tr_cnp = o_wta.clone(), t_wta.clone(), tr_wta.clone()\n",
    "\n",
    "                p_wta, g_wta = model_wta(o_wta, t_wta)\n",
    "                dec_id = torch.argmax(g_wta.squeeze(1), dim=-1)\n",
    "                vp_means = p_wta[dec_id, torch.arange(batch_size), :, :dy]\n",
    "                val_loss_wta += mse_loss(vp_means, tr_wta).item()\n",
    "\n",
    "                pred_cnp, encoded_rep = model_cnp(o_cnp, t_cnp)\n",
    "                val_loss_cnp += mse_loss(pred_cnp[:, :, :model_cnp.output_dim], tr_cnp)\n",
    "\n",
    "            validation_error_wta.append(val_loss_wta)\n",
    "            if val_loss_wta < min_val_loss_wta:\n",
    "                min_val_loss_wta = val_loss_wta\n",
    "                print(f'(WTA)New best: {min_val_loss_wta}')\n",
    "                torch.save(model_wta.state_dict(), f'{root_folder}saved_models/wta_on_synth.pt')\n",
    "\n",
    "            validation_error_cnp.append(val_loss_cnp.item())\n",
    "            if val_loss_cnp < min_val_loss_cnp:\n",
    "                min_val_loss_cnp = val_loss_cnp\n",
    "                print(f'(CNP)New best: {min_val_loss_cnp}')\n",
    "                torch.save(model_cnp.state_dict(), f'{root_folder}saved_models/cnp_on_synth.pt')\n",
    "\n",
    "\n",
    "    avg_loss_wta += epoch_loss_wta\n",
    "    avg_loss_cnp += epoch_loss_cnp\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: {}, WTA-Loss: {}, CNP-Loss: {}\".format(epoch, avg_loss_wta/100, avg_loss_cnp/100))\n",
    "        avg_loss_wta, avg_loss_cnp = 0, 0\n",
    "\n",
    "    if epoch % 100000:\n",
    "        torch.save(torch.Tensor(training_loss_wta), wta_tr_loss_path)\n",
    "        torch.save(torch.Tensor(validation_error_wta), wta_val_err_path)\n",
    "        torch.save(torch.Tensor(training_loss_cnp), cnp_tr_loss_path)\n",
    "        torch.save(torch.Tensor(validation_error_cnp), cnp_val_err_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.6432, 0.3532],\n",
       "          [0.6734, 0.3360],\n",
       "          [0.4623, 0.3938],\n",
       "          [0.5628, 0.3867]]], device='cuda:0'),\n",
       " tensor([[[0.5829],\n",
       "          [0.4372],\n",
       "          [0.1357],\n",
       "          [0.0553]]], device='cuda:0'),\n",
       " tensor([[[0.3786],\n",
       "          [0.3846],\n",
       "          [0.1637],\n",
       "          [0.0679]]], device='cuda:0'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_batch(x, y, torch.tensor([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7.1789e-04],\n",
       "         [ 4.3372e-03],\n",
       "         [ 1.0292e-02],\n",
       "         [ 1.2903e-02],\n",
       "         [ 1.7825e-02],\n",
       "         [ 2.1792e-02],\n",
       "         [ 2.8134e-02],\n",
       "         [ 3.0058e-02],\n",
       "         [ 3.7435e-02],\n",
       "         [ 3.9901e-02],\n",
       "         [ 4.2849e-02],\n",
       "         [ 5.1133e-02],\n",
       "         [ 5.1750e-02],\n",
       "         [ 5.5544e-02],\n",
       "         [ 6.0312e-02],\n",
       "         [ 6.5479e-02],\n",
       "         [ 6.8115e-02],\n",
       "         [ 7.2803e-02],\n",
       "         [ 7.6412e-02],\n",
       "         [ 8.0532e-02],\n",
       "         [ 8.4633e-02],\n",
       "         [ 9.1421e-02],\n",
       "         [ 9.4284e-02],\n",
       "         [ 9.6982e-02],\n",
       "         [ 1.0208e-01],\n",
       "         [ 1.0504e-01],\n",
       "         [ 1.0916e-01],\n",
       "         [ 1.1274e-01],\n",
       "         [ 1.1942e-01],\n",
       "         [ 1.2047e-01],\n",
       "         [ 1.2431e-01],\n",
       "         [ 1.3132e-01],\n",
       "         [ 1.3191e-01],\n",
       "         [ 1.4005e-01],\n",
       "         [ 1.4191e-01],\n",
       "         [ 1.4937e-01],\n",
       "         [ 1.4669e-01],\n",
       "         [ 1.5126e-01],\n",
       "         [ 1.5599e-01],\n",
       "         [ 1.5773e-01],\n",
       "         [ 1.6134e-01],\n",
       "         [ 1.6478e-01],\n",
       "         [ 1.6776e-01],\n",
       "         [ 1.7113e-01],\n",
       "         [ 1.7857e-01],\n",
       "         [ 1.7774e-01],\n",
       "         [ 1.8101e-01],\n",
       "         [ 1.8526e-01],\n",
       "         [ 1.8787e-01],\n",
       "         [ 1.9455e-01],\n",
       "         [ 1.9398e-01],\n",
       "         [ 1.9649e-01],\n",
       "         [ 2.0079e-01],\n",
       "         [ 2.0480e-01],\n",
       "         [ 2.0521e-01],\n",
       "         [ 2.1179e-01],\n",
       "         [ 2.1585e-01],\n",
       "         [ 2.1352e-01],\n",
       "         [ 2.1618e-01],\n",
       "         [ 2.1872e-01],\n",
       "         [ 2.2149e-01],\n",
       "         [ 2.2374e-01],\n",
       "         [ 2.2689e-01],\n",
       "         [ 2.2882e-01],\n",
       "         [ 2.3121e-01],\n",
       "         [ 2.3312e-01],\n",
       "         [ 2.3943e-01],\n",
       "         [ 2.3810e-01],\n",
       "         [ 2.3954e-01],\n",
       "         [ 2.4721e-01],\n",
       "         [ 2.4501e-01],\n",
       "         [ 2.4572e-01],\n",
       "         [ 2.4979e-01],\n",
       "         [ 2.4927e-01],\n",
       "         [ 2.5078e-01],\n",
       "         [ 2.5478e-01],\n",
       "         [ 2.5786e-01],\n",
       "         [ 2.5564e-01],\n",
       "         [ 2.5841e-01],\n",
       "         [ 2.5840e-01],\n",
       "         [ 2.5974e-01],\n",
       "         [ 2.6101e-01],\n",
       "         [ 2.6222e-01],\n",
       "         [ 2.6336e-01],\n",
       "         [ 2.6475e-01],\n",
       "         [ 2.6559e-01],\n",
       "         [ 2.6639e-01],\n",
       "         [ 2.6726e-01],\n",
       "         [ 2.6807e-01],\n",
       "         [ 2.6882e-01],\n",
       "         [ 2.6949e-01],\n",
       "         [ 2.7196e-01],\n",
       "         [ 2.7064e-01],\n",
       "         [ 2.7314e-01],\n",
       "         [ 2.7438e-01],\n",
       "         [ 2.7233e-01],\n",
       "         [ 2.7494e-01],\n",
       "         [ 2.7543e-01],\n",
       "         [ 2.7385e-01],\n",
       "         [ 2.7254e-01],\n",
       "         [ 2.7311e-01],\n",
       "         [ 2.7698e-01],\n",
       "         [ 2.7234e-01],\n",
       "         [ 2.7280e-01],\n",
       "         [ 2.7457e-01],\n",
       "         [ 2.7153e-01],\n",
       "         [ 2.7323e-01],\n",
       "         [ 2.7075e-01],\n",
       "         [ 2.7030e-01],\n",
       "         [ 2.6949e-01],\n",
       "         [ 2.7230e-01],\n",
       "         [ 2.6888e-01],\n",
       "         [ 2.6726e-01],\n",
       "         [ 2.6710e-01],\n",
       "         [ 2.6915e-01],\n",
       "         [ 2.6444e-01],\n",
       "         [ 2.6352e-01],\n",
       "         [ 2.6768e-01],\n",
       "         [ 2.6102e-01],\n",
       "         [ 2.6042e-01],\n",
       "         [ 2.6340e-01],\n",
       "         [ 2.5739e-01],\n",
       "         [ 2.5921e-01],\n",
       "         [ 2.5435e-01],\n",
       "         [ 2.5258e-01],\n",
       "         [ 2.5128e-01],\n",
       "         [ 2.5184e-01],\n",
       "         [ 2.4727e-01],\n",
       "         [ 2.4771e-01],\n",
       "         [ 2.4420e-01],\n",
       "         [ 2.4249e-01],\n",
       "         [ 2.4066e-01],\n",
       "         [ 2.3800e-01],\n",
       "         [ 2.3578e-01],\n",
       "         [ 2.3351e-01],\n",
       "         [ 2.3086e-01],\n",
       "         [ 2.2873e-01],\n",
       "         [ 2.2626e-01],\n",
       "         [ 2.2389e-01],\n",
       "         [ 2.2128e-01],\n",
       "         [ 2.1889e-01],\n",
       "         [ 2.1643e-01],\n",
       "         [ 2.1407e-01],\n",
       "         [ 2.1077e-01],\n",
       "         [ 2.0830e-01],\n",
       "         [ 2.0621e-01],\n",
       "         [ 2.0346e-01],\n",
       "         [ 2.0135e-01],\n",
       "         [ 1.9656e-01],\n",
       "         [ 1.9348e-01],\n",
       "         [ 1.9100e-01],\n",
       "         [ 1.9168e-01],\n",
       "         [ 1.8637e-01],\n",
       "         [ 1.8125e-01],\n",
       "         [ 1.8077e-01],\n",
       "         [ 1.7810e-01],\n",
       "         [ 1.7349e-01],\n",
       "         [ 1.6776e-01],\n",
       "         [ 1.6435e-01],\n",
       "         [ 1.6151e-01],\n",
       "         [ 1.5741e-01],\n",
       "         [ 1.5389e-01],\n",
       "         [ 1.5148e-01],\n",
       "         [ 1.4824e-01],\n",
       "         [ 1.4320e-01],\n",
       "         [ 1.3937e-01],\n",
       "         [ 1.3749e-01],\n",
       "         [ 1.3311e-01],\n",
       "         [ 1.2812e-01],\n",
       "         [ 1.3045e-01],\n",
       "         [ 1.2394e-01],\n",
       "         [ 1.1683e-01],\n",
       "         [ 1.1281e-01],\n",
       "         [ 1.0900e-01],\n",
       "         [ 1.0480e-01],\n",
       "         [ 1.0191e-01],\n",
       "         [ 9.6950e-02],\n",
       "         [ 9.2769e-02],\n",
       "         [ 8.8915e-02],\n",
       "         [ 8.4656e-02],\n",
       "         [ 8.2720e-02],\n",
       "         [ 8.2099e-02],\n",
       "         [ 7.5572e-02],\n",
       "         [ 6.8391e-02],\n",
       "         [ 6.5716e-02],\n",
       "         [ 5.9750e-02],\n",
       "         [ 5.5786e-02],\n",
       "         [ 5.1325e-02],\n",
       "         [ 4.7093e-02],\n",
       "         [ 4.3204e-02],\n",
       "         [ 3.8644e-02],\n",
       "         [ 3.4759e-02],\n",
       "         [ 3.5121e-02],\n",
       "         [ 2.7245e-02],\n",
       "         [ 2.1491e-02],\n",
       "         [ 1.7489e-02],\n",
       "         [ 2.0428e-02],\n",
       "         [ 1.4237e-02],\n",
       "         [ 4.5115e-03],\n",
       "         [ 1.4355e-04]],\n",
       "\n",
       "        [[-7.1789e-04],\n",
       "         [-4.3372e-03],\n",
       "         [-1.0292e-02],\n",
       "         [-1.2903e-02],\n",
       "         [-1.7825e-02],\n",
       "         [-2.1792e-02],\n",
       "         [-2.8134e-02],\n",
       "         [-3.0058e-02],\n",
       "         [-3.7435e-02],\n",
       "         [-3.9901e-02],\n",
       "         [-4.2849e-02],\n",
       "         [-5.1133e-02],\n",
       "         [-5.1750e-02],\n",
       "         [-5.5544e-02],\n",
       "         [-6.0312e-02],\n",
       "         [-6.5479e-02],\n",
       "         [-6.8115e-02],\n",
       "         [-7.2803e-02],\n",
       "         [-7.6412e-02],\n",
       "         [-8.0532e-02],\n",
       "         [-8.4633e-02],\n",
       "         [-9.1421e-02],\n",
       "         [-9.4284e-02],\n",
       "         [-9.6982e-02],\n",
       "         [-1.0208e-01],\n",
       "         [-1.0504e-01],\n",
       "         [-1.0916e-01],\n",
       "         [-1.1274e-01],\n",
       "         [-1.1942e-01],\n",
       "         [-1.2047e-01],\n",
       "         [-1.2431e-01],\n",
       "         [-1.3132e-01],\n",
       "         [-1.3191e-01],\n",
       "         [-1.4005e-01],\n",
       "         [-1.4191e-01],\n",
       "         [-1.4937e-01],\n",
       "         [-1.4669e-01],\n",
       "         [-1.5126e-01],\n",
       "         [-1.5599e-01],\n",
       "         [-1.5773e-01],\n",
       "         [-1.6134e-01],\n",
       "         [-1.6478e-01],\n",
       "         [-1.6776e-01],\n",
       "         [-1.7113e-01],\n",
       "         [-1.7857e-01],\n",
       "         [-1.7774e-01],\n",
       "         [-1.8101e-01],\n",
       "         [-1.8526e-01],\n",
       "         [-1.8787e-01],\n",
       "         [-1.9455e-01],\n",
       "         [-1.9398e-01],\n",
       "         [-1.9649e-01],\n",
       "         [-2.0079e-01],\n",
       "         [-2.0480e-01],\n",
       "         [-2.0521e-01],\n",
       "         [-2.1179e-01],\n",
       "         [-2.1585e-01],\n",
       "         [-2.1352e-01],\n",
       "         [-2.1618e-01],\n",
       "         [-2.1872e-01],\n",
       "         [-2.2149e-01],\n",
       "         [-2.2374e-01],\n",
       "         [-2.2689e-01],\n",
       "         [-2.2882e-01],\n",
       "         [-2.3121e-01],\n",
       "         [-2.3312e-01],\n",
       "         [-2.3943e-01],\n",
       "         [-2.3810e-01],\n",
       "         [-2.3954e-01],\n",
       "         [-2.4721e-01],\n",
       "         [-2.4501e-01],\n",
       "         [-2.4572e-01],\n",
       "         [-2.4979e-01],\n",
       "         [-2.4927e-01],\n",
       "         [-2.5078e-01],\n",
       "         [-2.5478e-01],\n",
       "         [-2.5786e-01],\n",
       "         [-2.5564e-01],\n",
       "         [-2.5841e-01],\n",
       "         [-2.5840e-01],\n",
       "         [-2.5974e-01],\n",
       "         [-2.6101e-01],\n",
       "         [-2.6222e-01],\n",
       "         [-2.6336e-01],\n",
       "         [-2.6475e-01],\n",
       "         [-2.6559e-01],\n",
       "         [-2.6639e-01],\n",
       "         [-2.6726e-01],\n",
       "         [-2.6807e-01],\n",
       "         [-2.6882e-01],\n",
       "         [-2.6949e-01],\n",
       "         [-2.7196e-01],\n",
       "         [-2.7064e-01],\n",
       "         [-2.7314e-01],\n",
       "         [-2.7438e-01],\n",
       "         [-2.7233e-01],\n",
       "         [-2.7494e-01],\n",
       "         [-2.7543e-01],\n",
       "         [-2.7385e-01],\n",
       "         [-2.7254e-01],\n",
       "         [-2.7311e-01],\n",
       "         [-2.7698e-01],\n",
       "         [-2.7234e-01],\n",
       "         [-2.7280e-01],\n",
       "         [-2.7457e-01],\n",
       "         [-2.7153e-01],\n",
       "         [-2.7323e-01],\n",
       "         [-2.7075e-01],\n",
       "         [-2.7030e-01],\n",
       "         [-2.6949e-01],\n",
       "         [-2.7230e-01],\n",
       "         [-2.6888e-01],\n",
       "         [-2.6726e-01],\n",
       "         [-2.6710e-01],\n",
       "         [-2.6915e-01],\n",
       "         [-2.6444e-01],\n",
       "         [-2.6352e-01],\n",
       "         [-2.6768e-01],\n",
       "         [-2.6102e-01],\n",
       "         [-2.6042e-01],\n",
       "         [-2.6340e-01],\n",
       "         [-2.5739e-01],\n",
       "         [-2.5921e-01],\n",
       "         [-2.5435e-01],\n",
       "         [-2.5258e-01],\n",
       "         [-2.5128e-01],\n",
       "         [-2.5184e-01],\n",
       "         [-2.4727e-01],\n",
       "         [-2.4771e-01],\n",
       "         [-2.4420e-01],\n",
       "         [-2.4249e-01],\n",
       "         [-2.4066e-01],\n",
       "         [-2.3800e-01],\n",
       "         [-2.3578e-01],\n",
       "         [-2.3351e-01],\n",
       "         [-2.3086e-01],\n",
       "         [-2.2873e-01],\n",
       "         [-2.2626e-01],\n",
       "         [-2.2389e-01],\n",
       "         [-2.2128e-01],\n",
       "         [-2.1889e-01],\n",
       "         [-2.1643e-01],\n",
       "         [-2.1407e-01],\n",
       "         [-2.1077e-01],\n",
       "         [-2.0830e-01],\n",
       "         [-2.0621e-01],\n",
       "         [-2.0346e-01],\n",
       "         [-2.0135e-01],\n",
       "         [-1.9656e-01],\n",
       "         [-1.9348e-01],\n",
       "         [-1.9100e-01],\n",
       "         [-1.9168e-01],\n",
       "         [-1.8637e-01],\n",
       "         [-1.8125e-01],\n",
       "         [-1.8077e-01],\n",
       "         [-1.7810e-01],\n",
       "         [-1.7349e-01],\n",
       "         [-1.6776e-01],\n",
       "         [-1.6435e-01],\n",
       "         [-1.6151e-01],\n",
       "         [-1.5741e-01],\n",
       "         [-1.5389e-01],\n",
       "         [-1.5148e-01],\n",
       "         [-1.4824e-01],\n",
       "         [-1.4320e-01],\n",
       "         [-1.3937e-01],\n",
       "         [-1.3749e-01],\n",
       "         [-1.3311e-01],\n",
       "         [-1.2812e-01],\n",
       "         [-1.3045e-01],\n",
       "         [-1.2394e-01],\n",
       "         [-1.1683e-01],\n",
       "         [-1.1281e-01],\n",
       "         [-1.0900e-01],\n",
       "         [-1.0480e-01],\n",
       "         [-1.0191e-01],\n",
       "         [-9.6950e-02],\n",
       "         [-9.2769e-02],\n",
       "         [-8.8915e-02],\n",
       "         [-8.4656e-02],\n",
       "         [-8.2720e-02],\n",
       "         [-8.2099e-02],\n",
       "         [-7.5572e-02],\n",
       "         [-6.8391e-02],\n",
       "         [-6.5716e-02],\n",
       "         [-5.9750e-02],\n",
       "         [-5.5786e-02],\n",
       "         [-5.1325e-02],\n",
       "         [-4.7093e-02],\n",
       "         [-4.3204e-02],\n",
       "         [-3.8644e-02],\n",
       "         [-3.4759e-02],\n",
       "         [-3.5121e-02],\n",
       "         [-2.7245e-02],\n",
       "         [-2.1491e-02],\n",
       "         [-1.7489e-02],\n",
       "         [-2.0428e-02],\n",
       "         [-1.4237e-02],\n",
       "         [-4.5115e-03],\n",
       "         [-1.4355e-04]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
